{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "# Lab assignment: classifying digits with Deep Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "<img src=\"img/mnist.jpeg\" style=\"width:480px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "In this assignment we will face the problem of recognizing handwritten digits. We will see how in order to achieve maximum effectiveness we will need to resort to several Deep Learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "## Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "Throughout this notebook you will find empty cells that you will need to fill with your own code. Follow the instructions in the notebook and pay special attention to the following symbols.\n",
    "\n",
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>You will need to solve a question by writing your own code or answer in the cell immediately below, or in a different file as instructed.</td></tr>\n",
    " <tr><td><img src=\"img/exclamation.png\" style=\"width:80px;height:80px;\"></td><td>This is a hint or useful observation that can help you solve this assignment. You are not expected to write any solution, but you should pay attention to them to understand the assignment.</td></tr>\n",
    " <tr><td><img src=\"img/pro.png\" style=\"width:80px;height:80px;\"></td><td>This is an advanced and voluntary exercise that can help you gain a deeper knowledge into the topic. Good luck!</td></tr>\n",
    "</table>\n",
    "\n",
    "During the assigment you will make use of several Python packages that might not be installed in your machine. If that is the case, you can install new Python packages with\n",
    "\n",
    "    conda install PACKAGENAME\n",
    "    \n",
    "if you are using Python Anaconda. Else you should use\n",
    "\n",
    "    pip install PACKAGENAME\n",
    "\n",
    "You will need the following packages for this particular assignment. Make sure they are available before proceeding:\n",
    "\n",
    "* **numpy**\n",
    "* **keras**\n",
    "* **matplotlib**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will embed any plots into the notebook instead of generating a new window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, if you need any help on the usage of a Python function you can place the writing cursor over its name and press Caps+Shift to produce a pop-out with related documentation. This will only work inside code cells. \n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Para familiarizarme con el funcionamiento de las redes neuronales voy a empezar viendo tres ejemplos de redes sencillas con conexiones hacia adelante (*feedforward*), es decir, redes en las que ninguna salida de las neuronas es entrada de neuronas del mismo nivel o niveles precedentes, sino que todas las neuronas de una capa reciben señales de entrada de otra capa anterior, más cercana a las entradas de la red, y envían las señales de salida a una capa posterior, más cercana a la salida de la red. Se trata por tanto de grafos dirigidos. Las redes con conexiones hacia atrás (*feedback*) que tienen lazos cerrados son sistemas recurrentes y no se trabajará con ellas en esta práctica.  \n",
    "Los tres ejemplos son las redes *feedforward* más conocidas: el perceptrón, la red ADALINE (ADAptative LINear Element) y *backpropagation*.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Perceptrón</span>\n",
    "\n",
    "<span style=\"color:blue\">Un tipo de aprendizaje supervisado es el aprendizaje por corrección del error, que consiste en ajustar los pesos de las conexiones de la red en función de la diferencia entre los valores deseados (de los cuales se dispone) y los obtenidos en la salida de la red; es decir, en función del error cometido en la salida. Un ejemplo de algoritmo simple de aprendizaje por corrección del error lo constituye la regla de aprendizaje del perceptrón (Rosenblatt, 1958):  </span>\n",
    "\n",
    "<span style=\"color:blue\">\\begin{equation}\\Delta w_b(t+1) = \\alpha x_b(t)[y(t)-f(t)]\\end{equation}</span>\n",
    "\n",
    "<span style=\"color:blue\">Siendo  \n",
    "$\\Delta w_b$: la variación en el peso de la conexión entre la neurona $b$ de entrada y la neurona de salida,  \n",
    "$x_b$: el valor ingresado en la neurona de entrada $b$,  \n",
    "$y$: el valor de salida deseado (el valor de la label),  \n",
    "$f$ : el valor de salida obtenido,  \n",
    "$\\alpha$ : el factor de aprendizaje ($0<\\alpha\\leq 1$) que regula la velocidad del aprendizaje,  \n",
    "$t$ : el número de paso; es una especie de tiempo discreto que toma valores naturales.</span>\n",
    "\n",
    "<span style=\"color:blue\">El preceptrón es el caso más simple de red neuronal: solo una capa de entrada y una de salida. Está formado por varias neuronas para recibir las entradas a la red y una neurona de salida. Es capaz de decidir cuándo una entrada presentada a la red pertenece a una de las dos clases que es capaz de reconocer. La única neurona de salida del perceptrón realiza la suma ponderada (combinación lineal) de las entradas (más un término independiente o *bias*, $w_0$) y pasa el resultado a una función de transferencia de tipo escalón:  \\begin{equation}f(z)=\\left\\{\\begin{array}{ll}\n",
    " 1 & \\mbox{ si $z\\geq 0$} \\\\\n",
    " 0 & \\mbox{ si $z< 0$} \\end{array} \\right. \\end{equation} </span>\n",
    " \n",
    "<span style=\"color:blue\">Se trata, por tanto, de un dispositivo de entradas y salidas digitales. Al ser tan simple, el perceptrón tiene una capacidad de representación bastante limitada; solo es capaz de discriminar patrones muy sencillos, linealmente separables.  \n",
    "Como ejemplo de funcionamiento de una red neuronal de tipo perceptrón voy a resolver el problema de la función OR. Para esta función la red debe ser capaz de devolver, a partir de los 4 patrones de entrada, {00, 01, 10, 11}, a qué clase pertenece cada uno. Esto es, para el patrón de entrada 00 debe devolver la clase 0 y para los restantes la clase 1. Las entradas (*features*) $x_1$ y $x_2$ serán dos valores binarios y la salida es:  \n",
    "\\begin{equation}a = f(w_0+w_1x_1+w_2x_2)=f\\left(\\sum_{b=0}^2 w_bx_b\\right),\\end{equation}  \n",
    "donde se ha compactado la notación haciendo $x_0=1.$ El esquema del perceptrón es el siguiente:</span>\n",
    "\n",
    "![perceptron](./Practica_AlgoritmosAvanzados_Pablo/perceptron.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Sean inicialmente los valores elegidos aleatoriamente:  \n",
    "    $w_0=1.5$  \n",
    "    $w_1=0.5$  \n",
    "    $w_2=1.5$  </span>\n",
    "    \n",
    "<span style=\"color:blue\">La tabla descriptiva del proceso al inicio es:\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & & & & 1.5 & 0.5 & 1.5 & & & \\end{array}  \n",
    "Se van tomando uno a uno los cuatro patrones de entrada. Empiezo por el primero, $x_1(t=1)=0,$ $x_2(1)=0,$ $y(1)=0$ y $x_0=1.$ Actualizo la tabla: \\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & & & \\end{array}  \n",
    "La combinación lineal que llega a la neurona de salida es:  \n",
    "\\begin{equation}a(1) =\\sum_{b=0}^2 w_b(1)x_b(1)= w_0(1)x_0+w_1(1)x_1(1)+w_2(1)x_2(1)=1'5\\cdot 1+0'5\\cdot 0+1'5\\cdot 0= 1'5.\\end{equation} Esta suma de productos no es más que un producto escalar, que, usando la notación vectorial/matricial, se puede escribir:  \n",
    "\\begin{equation}a(1)=\\mathbf{w(1)\\cdot x(1)} = (1.5, 0.5, 1.5)\\left(\\begin{array}{c}1\\\\ 0\\\\ 0 \\end{array}\\right)=1'5.\\end{equation}  \n",
    "La salida de la red, después de aplicar la función escalón, es:  \n",
    "$f(t=1)=1,$  </span>\n",
    "\n",
    "<span style=\"color:blue\">puesto que el argumento (1'5) es mayor que cero. Entonces, el error cometido en este primer paso es:  \n",
    "$\\epsilon(1)=y(1)-f(1)= 0-1=-1.$  </span>\n",
    "\n",
    "<span style=\"color:blue\">Lo incorporo a la tabla, que después de completar el primer paso queda así:  \n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1 \\end{array}  \n",
    "En el ejemplo de la operación OR se considera como factor de aprendizaje $\\alpha=1.$ Ahora se modifican los pesos según la expresión del algoritmo escrita más arriba, que con notación vectorial queda:  \n",
    "\\begin{equation}\\mathbf{w(2)}=\\mathbf{w(1)}+\\alpha\\epsilon(1)\\mathbf{x(1)}=\\left(\\begin{array}{c}1.5\\\\ 0.5\\\\ 1.5 \\end{array}\\right)+1\\cdot(-1)\\cdot\\left(\\begin{array}{c}1\\\\ 0\\\\ 0 \\end{array}\\right)=\\left(\\begin{array}{c}0.5\\\\ 0.5\\\\ 1.5 \\end{array}\\right).\\end{equation}  \n",
    "Entonces:  \n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & & & & 0.5 & 0.5 & 1.5 & & &\\end{array}  \n",
    "Comienzo ahora el segundo paso. El segundo patrón de entrada es $x_1(2)=0,$ $x_2(2)=1,$ $y(2)=1$ y $x_0=1:$  \n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & 0 & 1 & 1 & 0.5 & 0.5 & 1.5 & & &\\end{array}  \n",
    "La combinación lineal que llega a la neurona de salida, la salida de la red después de aplicar la función escalón y el error cometido en este segundo paso son, respectivamente:  \n",
    "$a(2)  = \\mathbf{w(2)\\cdot x(2)} = (0.5, 0.5, 1.5)\\left(\\begin{array}{c}1\\\\ 0\\\\ 1 \\end{array}\\right)=2,\\\\\n",
    "f(2)  =  1,\\\\\n",
    "\\epsilon(2)  = y(2)-f(2)= 0.$  \n",
    "\n",
    "<span style=\"color:blue\">Por tanto,   \n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & 0 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2 & 1 & 0\\end{array}\n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "Vuelvo a modificar los pesos. Como el error del segundo paso es cero, los pesos del tercer paso son iguales a los del segundo:  \n",
    "$\\mathbf{w(3)}=\\mathbf{w(2)}+\\alpha\\epsilon(2)\\mathbf{x(2)}=\\left(\\begin{array}{c}0.5\\\\ 0.5\\\\ 1.5 \\end{array}\\right)+1\\cdot 0\\cdot\\left(\\begin{array}{c}1\\\\ 0\\\\ 1 \\end{array}\\right)=\\left(\\begin{array}{c}0.5\\\\ 0.5\\\\ 1.5 \\end{array}\\right).$ Entonces:  \n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & 0 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2 & 1 & 0\\\\\n",
    "3 & & & & 0.5 & 0.5 & 1.5 & & &\\end{array}\n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "El tercer patrón es $x_1(3)=1,$ $x_2(3)=0,$ $y(3)=1$ y $x_0=1:$  \n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & 0 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2 & 1 & 0\\\\\n",
    "3 & 1 & 0 & 1 & 0.5 & 0.5 & 1.5 & & &\\end{array}  \n",
    "Vuelvo a calcular:  \n",
    "$a(3)  = \\mathbf{w(3)\\cdot x(3)} = (0.5, 0.5, 1.5)\\left(\\begin{array}{c}1\\\\ 1\\\\ 0 \\end{array}\\right)=1,\\\\\n",
    "f(3)  =  1,\\\\\n",
    "\\epsilon(3)  = y(3)-f(3)= 0.$\n",
    "  </span>\n",
    "  \n",
    "<span style=\"color:blue\">Por tanto,   \n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & 0 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2 & 1 & 0\\\\\n",
    "3 & 1 & 0 & 1 & 0.5 & 0.5 & 1.5 & 1 & 1 & 0\\end{array}\n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "Como el error del tercer paso también es cero, los pesos del cuarto paso son iguales a los del tercero:  \n",
    "$\\mathbf{w(4)}=\\mathbf{w(3)}=\\left(\\begin{array}{c}0.5\\\\ 0.5\\\\ 1.5 \\end{array}\\right).$ Entonces:  \n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & 0 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2 & 1 & 0\\\\\n",
    "3 & 1 & 0 & 1 & 0.5 & 0.5 & 1.5 & 1 & 1 & 0\\\\\n",
    "4 & & & & 0.5 & 0.5 & 1.5 & & &\\end{array}  \n",
    "Introduzco el cuarto patrón en la red: $x_1(4)=1,$ $x_2(4)=1,$ $y(4)=1$ y $x_0=1:$\n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & 0 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2 & 1 & 0\\\\\n",
    "3 & 1 & 0 & 1 & 0.5 & 0.5 & 1.5 & 1 & 1 & 0\\\\\n",
    "4 & 1 & 1 & 1 & 0.5 & 0.5 & 1.5 & & &\\end{array}\n",
    "Se procede igual:  \n",
    "$a(4)  = \\mathbf{w(4)\\cdot x(4)} = (0.5, 0.5, 1.5)\\left(\\begin{array}{c}1\\\\ 1\\\\ 1 \\end{array}\\right)=2.5,\\\\\n",
    "f(4)  =  1,\\\\\n",
    "\\epsilon(4)  = y(4)-f(4)= 0.$  \n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "Entonces,  \n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & 0 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2 & 1 & 0\\\\\n",
    "3 & 1 & 0 & 1 & 0.5 & 0.5 & 1.5 & 1 & 1 & 0\\\\\n",
    "4 & 1 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2.5 & 1 & 0\\end{array}  \n",
    "Ya se ha iterado el procedimiento con todos los patrones de entrada. Existe uno, 00, para el que el error cometido no es cero. Por consiguiente, se aplica de nuevo el algoritmo con todos los patrones de entrada.\n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "Como el error del 4º paso también es cero, los pesos del 5º paso son iguales a los del 4º:  \n",
    "$\\mathbf{w(5)}=\\mathbf{w(4)}=\\left(\\begin{array}{c}0.5\\\\ 0.5\\\\ 1.5 \\end{array}\\right).$   \n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & 0 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2 & 1 & 0\\\\\n",
    "3 & 1 & 0 & 1 & 0.5 & 0.5 & 1.5 & 1 & 1 & 0\\\\\n",
    "4 & 1 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2.5 & 1 & 0\\\\ \n",
    "\\hline\n",
    "5 & & & & 0.5 & 0.5 & 1.5 & & &\\end{array}  \n",
    "Introduzco otra vez el primer patrón en la red: $x_1(5)=0,$ $x_2(5)=0,$ $y(5)=0$ y $x_0=1:$\n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & 0 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2 & 1 & 0\\\\\n",
    "3 & 1 & 0 & 1 & 0.5 & 0.5 & 1.5 & 1 & 1 & 0\\\\\n",
    "4 & 1 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2.5 & 1 & 0\\\\\n",
    "\\hline\n",
    "5 & 0 & 0 & 0 & 0.5 & 0.5 & 1.5 & & &\\end{array} \n",
    "Se tiene:  \n",
    "$a(5)  = \\mathbf{w(5)\\cdot x(5)} = (0.5, 0.5, 1.5)\\left(\\begin{array}{c}1\\\\ 0\\\\ 0 \\end{array}\\right)=0.5,\\\\\n",
    "f(5)  =  1,\\\\\n",
    "\\epsilon(5)  = y(5)-f(5)= -1.$  \n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "Entonces,  \n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & 0 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2 & 1 & 0\\\\\n",
    "3 & 1 & 0 & 1 & 0.5 & 0.5 & 1.5 & 1 & 1 & 0\\\\\n",
    "4 & 1 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2.5 & 1 & 0\\\\\n",
    "\\hline\n",
    "5 & 0 & 0 & 0 & 0.5 & 0.5 & 1.5 & 0.5 & 1 & -1\\end{array}   \n",
    "Actualizo los pesos:  \n",
    "$\\mathbf{w(6)}=\\mathbf{w(5)}+\\alpha\\epsilon(5)\\mathbf{x(5)}=\\left(\\begin{array}{c}0.5\\\\ 0.5\\\\ 1.5 \\end{array}\\right)+1\\cdot(-1)\\cdot\\left(\\begin{array}{c}1\\\\ 0\\\\ 0 \\end{array}\\right)=\\left(\\begin{array}{c}-0.5\\\\ 0.5\\\\ 1.5 \\end{array}\\right):$  \n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & 0 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2 & 1 & 0\\\\\n",
    "3 & 1 & 0 & 1 & 0.5 & 0.5 & 1.5 & 1 & 1 & 0\\\\\n",
    "4 & 1 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2.5 & 1 & 0\\\\\n",
    "\\hline\n",
    "5 & 0 & 0 & 0 & 0.5 & 0.5 & 1.5 & 0.5 & 1 & -1\\\\\n",
    "6 & & & & -0.5 & 0.5 & 1.5 & & &\\end{array}  \n",
    "El siguiente patrón es: $x_1(6)=0,$ $x_2(6)=1,$ $y(6)=1$ y $x_0=1:$\n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & 0 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2 & 1 & 0\\\\\n",
    "3 & 1 & 0 & 1 & 0.5 & 0.5 & 1.5 & 1 & 1 & 0\\\\\n",
    "4 & 1 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2.5 & 1 & 0\\\\\n",
    "\\hline\n",
    "5 & 0 & 0 & 0 & 0.5 & 0.5 & 1.5 & 0.5 & 1 & -1\\\\\n",
    "6 & 0 & 1 & 1 & -0.5 & 0.5 & 1.5 & & &\\end{array}  \n",
    "Se puede comprobar que el error para este patrón y los dos siguientes es cero y, por tanto, los pesos no se ven modificados. Procediendo como hasta ahora, al final de la segunda vuelta la tabla queda:  \n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & 0 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2 & 1 & 0\\\\\n",
    "3 & 1 & 0 & 1 & 0.5 & 0.5 & 1.5 & 1 & 1 & 0\\\\\n",
    "4 & 1 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2.5 & 1 & 0\\\\\n",
    "\\hline\n",
    "5 & 0 & 0 & 0 & 0.5 & 0.5 & 1.5 & 0.5 & 1 & -1\\\\\n",
    "6 & 0 & 1 & 1 & -0.5 & 0.5 & 1.5 & 1 & 1 & 0\\\\\n",
    "7 & 1 & 0 & 1 & -0.5 & 0.5 & 1.5 & 0 & 1 & 0\\\\\n",
    "8 & 1 & 1 & 1 & -0.5 & 0.5 & 1.5 & 1.5 & 1 & 0\n",
    "\\end{array}.  \n",
    "De nuevo, el error cometido para el patrón 00 no es cero. Por consiguiente, se hace una tercera vuelta con todos los patrones de entrada. Al final de ella, la tabla queda:  \n",
    "\\begin{array}{c|ccc|ccc|c|c|c}\n",
    "t & x_1 & x_2 & y & w_0 & w_1 & w_2 & a & f & \\epsilon\\\\\n",
    "\\hline\n",
    "1 & 0 & 0 & 0 & 1.5 & 0.5 & 1.5 & 1.5 & 1 & -1\\\\\n",
    "2 & 0 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2 & 1 & 0\\\\\n",
    "3 & 1 & 0 & 1 & 0.5 & 0.5 & 1.5 & 1 & 1 & 0\\\\\n",
    "4 & 1 & 1 & 1 & 0.5 & 0.5 & 1.5 & 2.5 & 1 & 0\\\\\n",
    "\\hline\n",
    "5 & 0 & 0 & 0 & 0.5 & 0.5 & 1.5 & 0.5 & 1 & -1\\\\\n",
    "6 & 0 & 1 & 1 & -0.5 & 0.5 & 1.5 & 1 & 1 & 0\\\\\n",
    "7 & 1 & 0 & 1 & -0.5 & 0.5 & 1.5 & 0 & 1 & 0\\\\\n",
    "8 & 1 & 1 & 1 & -0.5 & 0.5 & 1.5 & 1.5 & 1 &0\\\\\n",
    "\\hline\n",
    "9 & 0 & 0 & 0 & -0.5 & 0.5 & 1.5 & -0.5 & 0 & 0\\\\\n",
    "10 & 0 & 1 & 1 & -0.5 & 0.5 & 1.5 & 1 & 1 & 0\\\\\n",
    "11 & 1 & 0 & 1 & -0.5 & 0.5 & 1.5 & 0 & 1 & 0\\\\\n",
    "12 & 1 & 1 & 1 & -0.5 & 0.5 & 1.5 & 1.5 & 1 & 0\n",
    "\\end{array}.  \n",
    "Como ya no se comete ningún error, la etapa de aprendizaje concluye. Los pesos finales son los que aparecen en la última fila.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Una vez vista la teoría con ejemplo incluido, voy a montar un perceptrón con keras. Le paso los mismos pesos iniciales que en el ejemplo, genero una instancia del optimizador Stochastic Gradient Descent (SGD) con tasa de aprendizaje lr = 1 como en el ejemplo y emulo la función de activación escalón con una función sigmoide.  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_153 (Dense)                (None, 1)             3           dense_input_138[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_149 (Activation)      (None, 1)             0           dense_153[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "uves = np.array([[0.5],\n",
    "        [1.5]]).reshape(2,1)\n",
    "bias=np.array([1.5]).reshape(1,)\n",
    "pesos=[uves,bias]\n",
    "\n",
    "perceptron=Sequential()\n",
    "perceptron.add(Dense(1, input_shape=(2,), weights = pesos))\n",
    "perceptron.add(Activation('sigmoid'))\n",
    "\n",
    "perceptron.summary()\n",
    "\n",
    "#rms=RMSprop(lr=1)\n",
    "sgd=SGD(lr=1)\n",
    "#adam=Adam(lr=1)\n",
    "perceptron.compile(loss='binary_crossentropy',\n",
    "               optimizer=sgd,\n",
    "                  metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx=np.array([[0,0],[0,1],[1,0],[1,1]]).reshape((4,2))\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yy=[0,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4s - loss: 0.4767 - acc: 0.7500\n",
      "Epoch 2/30\n",
      "0s - loss: 0.4516 - acc: 0.7500\n",
      "Epoch 3/30\n",
      "0s - loss: 0.4295 - acc: 0.7500\n",
      "Epoch 4/30\n",
      "0s - loss: 0.4100 - acc: 0.7500\n",
      "Epoch 5/30\n",
      "0s - loss: 0.3929 - acc: 0.7500\n",
      "Epoch 6/30\n",
      "0s - loss: 0.3777 - acc: 0.7500\n",
      "Epoch 7/30\n",
      "0s - loss: 0.3640 - acc: 0.7500\n",
      "Epoch 8/30\n",
      "0s - loss: 0.3517 - acc: 0.7500\n",
      "Epoch 9/30\n",
      "0s - loss: 0.3405 - acc: 0.7500\n",
      "Epoch 10/30\n",
      "0s - loss: 0.3302 - acc: 0.7500\n",
      "Epoch 11/30\n",
      "0s - loss: 0.3206 - acc: 0.7500\n",
      "Epoch 12/30\n",
      "0s - loss: 0.3117 - acc: 0.7500\n",
      "Epoch 13/30\n",
      "0s - loss: 0.3033 - acc: 0.7500\n",
      "Epoch 14/30\n",
      "0s - loss: 0.2955 - acc: 0.7500\n",
      "Epoch 15/30\n",
      "0s - loss: 0.2880 - acc: 0.7500\n",
      "Epoch 16/30\n",
      "0s - loss: 0.2809 - acc: 0.7500\n",
      "Epoch 17/30\n",
      "0s - loss: 0.2742 - acc: 0.7500\n",
      "Epoch 18/30\n",
      "0s - loss: 0.2677 - acc: 0.7500\n",
      "Epoch 19/30\n",
      "0s - loss: 0.2616 - acc: 1.0000\n",
      "Epoch 20/30\n",
      "0s - loss: 0.2557 - acc: 1.0000\n",
      "Epoch 21/30\n",
      "0s - loss: 0.2501 - acc: 1.0000\n",
      "Epoch 22/30\n",
      "0s - loss: 0.2447 - acc: 1.0000\n",
      "Epoch 23/30\n",
      "0s - loss: 0.2395 - acc: 1.0000\n",
      "Epoch 24/30\n",
      "0s - loss: 0.2346 - acc: 1.0000\n",
      "Epoch 25/30\n",
      "0s - loss: 0.2298 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "0s - loss: 0.2252 - acc: 1.0000\n",
      "Epoch 27/30\n",
      "0s - loss: 0.2208 - acc: 1.0000\n",
      "Epoch 28/30\n",
      "0s - loss: 0.2165 - acc: 1.0000\n",
      "Epoch 29/30\n",
      "0s - loss: 0.2124 - acc: 1.0000\n",
      "Epoch 30/30\n",
      "0s - loss: 0.2085 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x55492f60>"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.fit(\n",
    "    xx, # Training data\n",
    "    yy, # Labels of training data\n",
    "    #batch_size=128, # Batch size for the optimizer algorithm\n",
    "    nb_epoch=30, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_per = perceptron.evaluate(xx, yy)\n",
    "accuracy_per[0]\n",
    "accuracy_per[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.06366944],\n",
       "        [ 2.4770968 ]], dtype=float32), array([-0.41536373], dtype=float32)]"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Después de varias rondas el modelo es capaz de predecir al 100% la función OR. Los pesos recuperados al final no son exactamente los mismos que los obtenidos en el ejemplo de arriba porque, entre otras cosas, la función de activación no es la misma.  \n",
    "Existen otros algoritmos más evolucionados que el expuesto aquí. Este presenta algunas limitaciones como el no considerar la magnitud del error global cometido durante el proceso completo de aprendizaje de la red, sino considerando únicamente los errores individuales (locales) correspondientes al aprendizaje de cada patrón de muestra por separado. Un algoritmo muy conocido que mejora el del perceptrón es la regla delta o regla del mínimo error cuadrático medio (Widrow-Hoff, 1960), que se aplicó en las redes desarrolladas por los mismos autores, conocidas como ADALINE (ADAptative LINear Element), con una única neurona de salida y MADALINE (Multiple ADALINE), con varias neuronas de salida.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">ADALINE</span>\n",
    "\n",
    "<span style=\"color:blue\">Widrow y Hoff definieron una función que permitía cuantificar el error global cometido en cualquier momento durante el proceso de entrenamiento de la red, lo cual es importante, puesto que cuanta más información se tenga sobre el error cometido, más rápido se puede aprender. Este error medio se expresa de esta forma:  \n",
    "\\begin{equation}E=\\frac{1}{N}\\sum_{i=1}^N\\frac{1}{2}\\left[y_i-f(\\mathbf{x_i;w})\\right]^2=\\frac{1}{N}\\sum_{i=1}^N\\frac{1}{2}\\left(y_i-\\sum_{a=0}^m w_a x_{ia}\\right)^2.\\end{equation}  \n",
    "Donde $N$ es el número de informaciones que debe aprender la red, $m$ es el número de neuronas de entrada, $w_a$ son los pesos que hay que hallar ($w_0$ es el bias, al que corresponde $x_{i0}=1$), $x_{ia}$ es la componente a-ésima del patrón i-ésimo que entra a la neurona de entrada $a$ (los subíndices del principio del abecedario se refieren a las neuronas, mientras que los de enmedio del abecedario se refieren a los patrones de muestra), $y_i$ es la salida deseada del patrón i-ésimo (el valor i-ésimo de la variable objetivo), y $f(\\mathbf{x_i;w})$ es la salida obtenida a partir del patrón de entrenamiento i-ésimo. Entonces, la cantidad $1/2 [y_i-f(\\mathbf{x_i;w})]^2$ es el error cometido en el aprendizaje de la información (muestra) i-ésima. Se trata, por tanto, de encontrar unos pesos que minimicen esta función de error.  \n",
    "La estructura de las redes ADALINE y MADALINE es casi idéntica a la del perceptrón elemental. La diferencia fundamental se refiere al mecanismo de aprendizaje. ADALINE emplea la regla Delta, buscando el mínimo de la anterior expresión del error entre la salida deseada y la salida lineal obtenida antes de aplicarle la función de activación, mientras que el perceptrón arroja una salida binaria. Debido a esta nueva forma de evaluar el error, estas redes pueden procesar información analógica, tanto de entrada como de salida. En cambio, el perceptrón es un dispositivo digital.  \n",
    "Si la función de activación de la neurona de salida de ADALINE es la identidad, esta red da una salida lineal (combinación lineal de las entradas) y, por tanto, lo que hace la red al ajustar los pesos en el proceso de aprendizaje no es más que una **regresión lineal**. En este caso se puede resolver el problema de optimización del error de forma analítica como se muestra a continuación.  \n",
    "Para minimizar la función de error hay que igualar a cero sus derivadas parciales respecto a los pesos que se quieren hallar, es decir, hay que hacer cero el gradiente de la función de error, $\\mathbf{\\nabla_{w} E}=0.$ Para el caso de solo dos features, es decir, solo dos neuronas de entrada:  \n",
    "\\begin{eqnarray}0&=&\\frac{\\partial E}{\\partial w_0}=\\frac{2}{2N}\\sum_{i=1}^N (y_i-w_0-w_1x_{i1}-w_2x_{i2})\\cdot (-1)\\\\\n",
    "0&=&\\frac{\\partial E}{\\partial w_1}=\\frac{2}{2N}\\sum_{i=1}^N (y_i-w_0-w_1x_{i1}-w_2x_{i2})\\cdot (-x_{i1})\\\\\n",
    "0&=&\\frac{\\partial E}{\\partial w_2}=\\frac{2}{2N}\\sum_{i=1}^N (y_i-w_0-w_1x_{i1}-w_2x_{i2})\\cdot (-x_{i2})\n",
    "\\end{eqnarray}  \n",
    "Reordenando términos se tiene:  \n",
    "\\begin{eqnarray}\n",
    "\\sum_{i=1}^N w_0 + w_1\\sum_{i=1}^N x_{i1}+ w_2\\sum_{i=1}^N x_{i2}&=&\\sum_{i=1}^N y_i\\\\\n",
    "w_0 \\sum_{i=1}^N x_{i1}+ w_1\\sum_{i=1}^N x_{i1}^2+ w_2\\sum_{i=1}^N x_{i1}x_{i2}&=&\\sum_{i=1}^N x_{i1}y_i\\\\\n",
    "w_0 \\sum_{i=1}^N x_{i2}+ w_1\\sum_{i=1}^N x_{i1}x_{i2}+ w_2\\sum_{i=1}^N x_{i2}^2&=&\\sum_{i=1}^N x_{i2}y_i\n",
    "\\end{eqnarray}  \n",
    "Que, en notación matricial, puede escribirse como:  \n",
    "\\begin{equation}\n",
    "\\begin{pmatrix}\n",
    "N & \\sum x_{i1} & \\sum x_{i2}\\\\\n",
    "\\sum x_{i1} & \\sum x_{i1}^2 & \\sum x_{i1}x_{i2}\\\\\n",
    "\\sum x_{i2} & \\sum x_{i1}x_{i2} & \\sum x_{i2}^2\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "w_0 \\\\\n",
    "w_1 \\\\\n",
    "w_2\n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix}\n",
    "\\sum y_i \\\\\n",
    "\\sum x_{i1}y_i \\\\\n",
    "\\sum x_{i2}y_i\n",
    "\\end{pmatrix}\n",
    "\\end{equation}  \n",
    "O de manera más compacta aún:  \n",
    "\\begin{pmatrix}\n",
    "N & \\sum x_{i1} & \\sum x_{i2} & | & \\sum y_i \\\\\n",
    "\\sum x_{i1} & \\sum x_{i1}^2 & \\sum x_{i1}x_{i2} & | & \\sum x_{i1}y_i \\\\\n",
    "\\sum x_{i2} & \\sum x_{i1}x_{i2} & \\sum x_{i2}^2 & | & \\sum x_{i2}y_i\n",
    "\\end{pmatrix}  \n",
    "Donde se ha sustituido la matriz de incógnitas (pesos) y el símbolo de igualdad por una línea vertical discontinua. Esta matriz representa un sistema lineal de ecuaciones. Una forma de resolverlo es mediante el sistema de Gauss. Se sustituye la segunda fila (ecuación) por la resta de la segunda fila multiplicada por $N$ y la primera multiplicada por $\\sum x_{i1},$ y la tercera fila por la resta de la tercera fila multiplicada por $N$ y la primera multiplicada por $\\sum x_{i2}.$ Así se consigue ir haciendo cero todos los elementos debajo de la diagonal principal y, por tanto, triangular la matriz. Después solo queda despejar las incógnitas hacia atrás, empezando por $w_2.$ Quedan las siguientes expresiones:  \n",
    "\n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "\\begin{eqnarray}\n",
    "w_2 & = & \\frac{\\left[ N \\sum x_{i1}^2 - \\left(\\sum x_{i1}\\right)^2\\right]\\left(N \\sum x_{i2}y_i - \\sum x_{i2}\\sum y_j\\right) - \\left(N \\sum x_{i1}x_{i2} - \\sum x_{i1}\\sum x_{j2}\\right)\\left(N \\sum x_{i1}y_i - \\sum x_{i1}\\sum y_j\\right)}{\\left[ N \\sum x_{i1}^2 - \\left(\\sum x_{i1}\\right)^2\\right]\\left[ N \\sum x_{i2}^2 - \\left(\\sum x_{i2}\\right)^2\\right] - \n",
    "\\left(N \\sum x_{i1}x_{i2} - \\sum x_{i1}\\sum x_{j2}\\right)^2} \\\\\n",
    "\\\\\n",
    "w_1 & = & \\frac{N \\sum x_{i1}y_i - \\sum x_{i1}\\sum y_j - \\left(N \\sum x_{i1}x_{i2} - \\sum x_{i1}\\sum x_{j2}\\right)w_2}{ N \\sum x_{i1}^2 - \\left(\\sum x_{i1}\\right)^2} \\\\\n",
    "\\\\\n",
    "w_0 & = & \\frac{1}{N}\\left(\\sum y_i - w_2\\sum x_{i2} - w_1\\sum x_{i1}\\right) = \\bar{y} - w_1 \\bar{x}_1  - w_2 \\bar{x}_2\n",
    "\\end{eqnarray}  \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Otra manera de resolver el problema pasa por emplear la notación matricial desde el principio. La función de error global puede escribirse:  \n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "\\begin{equation}E=\\frac{1}{2N}\\sum_{i=1}^N\\left(y_i-\\sum_{a=0}^m w_a x_{ia}\\right)^2=\\frac{1}{2N}\\sum_{i=1}^N\\left(y_i-\\sum_{a=0}^m w_a x_{ia}\\right)\\left(y_i-\\sum_{a=0}^m w_a x_{ia}\\right)=\\frac{1}{2N}\\left(Y-X\\cdot W\\right)^T\\left(Y-X\\cdot W\\right).\\end{equation}  \n",
    "Donde $Y$ es la matriz columna (dimensión N x 1) que contiene los $N$ valores de la *target* $y,$ $W$ es la matriz columna de dimensiones (m+1) x 1 que contiene los pesos y $X$ es la matriz de dimensiones N x (m+1) que contiene una columna de N unos y m columnas con los N valores de sendas *features*. En este caso, la matriz $X$ tiene 3 columnas y $W$ es de 3 x 1. Usando la regla de derivación de un producto la condición de minimización queda:  \n",
    "\\begin{equation}0=\\frac{\\partial E}{\\partial W}=\\frac{1}{2N}\\left[\\left(\\frac{\\partial}{\\partial W}Y-\\frac{\\partial}{\\partial W}X\\cdot W\\right)^T\\left(Y-X\\cdot W\\right)+\\left(Y-X\\cdot W\\right)^T\\left(\\frac{\\partial}{\\partial W}Y-\\frac{\\partial}{\\partial W}X\\cdot W\\right)\\right]=-\\frac{1}{2N}\\left[X^T\\left(Y-X\\cdot W\\right)+\\left(Y-X\\cdot W\\right)^T X\\right]=-\\frac{1}{N}X^T\\left(Y-X\\cdot W\\right)=\\frac{1}{N}(-X^T Y+X^T XW).\\end{equation}  \n",
    "En el penúltimo paso se ha utilizado la propiedad de la transposición de un producto de matrices, $(AB)^T=B^T A^T.$ Despejando la matriz de pesos se obtiene:  \n",
    "\\begin{equation}W=(X^TX)^{-1}X^TY\\end{equation}  \n",
    "Voy a generar un conjunto de datos de ejemplo para aplicar las expresiones anteriores. Para ello voy a usar la función $f(x_1,x_2)=2x_1+3x_2-4.$  \n",
    "**Advertencia.** Para generar conjuntos de datos sintéticos es habitual usar valores enteros para las *features* que están en progresión aritmética. Puede demostrarse que si se hace esto, el denominador de la expresión de $w_2$ se anula, independientemente de cuáles sean las diferencias de ambas progresiones aritméticas.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(50, 1)\n",
      "(50, 1)\n",
      "(50, 3)\n",
      "(50, 1)\n",
      "[[ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]\n",
      " [11]\n",
      " [12]\n",
      " [13]\n",
      " [14]\n",
      " [15]\n",
      " [16]\n",
      " [17]\n",
      " [18]\n",
      " [19]\n",
      " [20]\n",
      " [21]\n",
      " [22]\n",
      " [23]\n",
      " [24]\n",
      " [25]\n",
      " [26]\n",
      " [27]\n",
      " [28]\n",
      " [29]\n",
      " [30]\n",
      " [31]\n",
      " [32]\n",
      " [33]\n",
      " [34]\n",
      " [35]\n",
      " [36]\n",
      " [37]\n",
      " [38]\n",
      " [39]\n",
      " [40]\n",
      " [41]\n",
      " [42]\n",
      " [43]\n",
      " [44]\n",
      " [45]\n",
      " [46]\n",
      " [47]\n",
      " [48]\n",
      " [49]\n",
      " [50]]\n",
      "[[ -4]\n",
      " [ -2]\n",
      " [  0]\n",
      " [  2]\n",
      " [  4]\n",
      " [  6]\n",
      " [  8]\n",
      " [ 10]\n",
      " [ 12]\n",
      " [ 14]\n",
      " [ 16]\n",
      " [ 18]\n",
      " [ 20]\n",
      " [ 22]\n",
      " [ 24]\n",
      " [ 26]\n",
      " [ 28]\n",
      " [ 30]\n",
      " [ 32]\n",
      " [ 34]\n",
      " [ 36]\n",
      " [ 38]\n",
      " [ 40]\n",
      " [ 42]\n",
      " [ 44]\n",
      " [200]\n",
      " [201]\n",
      " [202]\n",
      " [203]\n",
      " [204]\n",
      " [205]\n",
      " [206]\n",
      " [207]\n",
      " [208]\n",
      " [209]\n",
      " [210]\n",
      " [211]\n",
      " [212]\n",
      " [213]\n",
      " [214]\n",
      " [215]\n",
      " [216]\n",
      " [217]\n",
      " [218]\n",
      " [219]\n",
      " [220]\n",
      " [221]\n",
      " [222]\n",
      " [223]\n",
      " [224]]\n",
      "[[   1.    1.   -4.]\n",
      " [   1.    2.   -2.]\n",
      " [   1.    3.    0.]\n",
      " [   1.    4.    2.]\n",
      " [   1.    5.    4.]\n",
      " [   1.    6.    6.]\n",
      " [   1.    7.    8.]\n",
      " [   1.    8.   10.]\n",
      " [   1.    9.   12.]\n",
      " [   1.   10.   14.]\n",
      " [   1.   11.   16.]\n",
      " [   1.   12.   18.]\n",
      " [   1.   13.   20.]\n",
      " [   1.   14.   22.]\n",
      " [   1.   15.   24.]\n",
      " [   1.   16.   26.]\n",
      " [   1.   17.   28.]\n",
      " [   1.   18.   30.]\n",
      " [   1.   19.   32.]\n",
      " [   1.   20.   34.]\n",
      " [   1.   21.   36.]\n",
      " [   1.   22.   38.]\n",
      " [   1.   23.   40.]\n",
      " [   1.   24.   42.]\n",
      " [   1.   25.   44.]\n",
      " [   1.   26.  200.]\n",
      " [   1.   27.  201.]\n",
      " [   1.   28.  202.]\n",
      " [   1.   29.  203.]\n",
      " [   1.   30.  204.]\n",
      " [   1.   31.  205.]\n",
      " [   1.   32.  206.]\n",
      " [   1.   33.  207.]\n",
      " [   1.   34.  208.]\n",
      " [   1.   35.  209.]\n",
      " [   1.   36.  210.]\n",
      " [   1.   37.  211.]\n",
      " [   1.   38.  212.]\n",
      " [   1.   39.  213.]\n",
      " [   1.   40.  214.]\n",
      " [   1.   41.  215.]\n",
      " [   1.   42.  216.]\n",
      " [   1.   43.  217.]\n",
      " [   1.   44.  218.]\n",
      " [   1.   45.  219.]\n",
      " [   1.   46.  220.]\n",
      " [   1.   47.  221.]\n",
      " [   1.   48.  222.]\n",
      " [   1.   49.  223.]\n",
      " [   1.   50.  224.]]\n",
      "[[-14]\n",
      " [ -6]\n",
      " [  2]\n",
      " [ 10]\n",
      " [ 18]\n",
      " [ 26]\n",
      " [ 34]\n",
      " [ 42]\n",
      " [ 50]\n",
      " [ 58]\n",
      " [ 66]\n",
      " [ 74]\n",
      " [ 82]\n",
      " [ 90]\n",
      " [ 98]\n",
      " [106]\n",
      " [114]\n",
      " [122]\n",
      " [130]\n",
      " [138]\n",
      " [146]\n",
      " [154]\n",
      " [162]\n",
      " [170]\n",
      " [178]\n",
      " [648]\n",
      " [653]\n",
      " [658]\n",
      " [663]\n",
      " [668]\n",
      " [673]\n",
      " [678]\n",
      " [683]\n",
      " [688]\n",
      " [693]\n",
      " [698]\n",
      " [703]\n",
      " [708]\n",
      " [713]\n",
      " [718]\n",
      " [723]\n",
      " [728]\n",
      " [733]\n",
      " [738]\n",
      " [743]\n",
      " [748]\n",
      " [753]\n",
      " [758]\n",
      " [763]\n",
      " [768]]\n"
     ]
    }
   ],
   "source": [
    "x1_sintetico = np.arange(1,51).reshape(50,1)\n",
    "x2_sintetico_a = np.arange(-4,46,2).reshape(25,1)\n",
    "x2_sintetico_b = np.arange(200,225).reshape(25,1)\n",
    "x2_sintetico = np.concatenate((x2_sintetico_a, x2_sintetico_b),axis=0)\n",
    "X_sintetico = np.concatenate((np.ones((50,1)),x1_sintetico,x2_sintetico),axis=1)\n",
    "y_sintetico = 2*x1_sintetico + 3*x2_sintetico - 4\n",
    "print(type(x1_sintetico))\n",
    "print(type(x2_sintetico))\n",
    "print(type(X_sintetico))\n",
    "print(type(y_sintetico))\n",
    "print(x1_sintetico.shape)\n",
    "print(x2_sintetico.shape)\n",
    "print(X_sintetico.shape)\n",
    "print(y_sintetico.shape)\n",
    "print(x1_sintetico)\n",
    "print(x2_sintetico)\n",
    "print(X_sintetico)\n",
    "print(y_sintetico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Como los datos son exactos, la matriz de pesos $W$ estará formada por los coeficientes de la función empleada: -4, 2 y 3.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3, 1)\n",
      "[[-4.]\n",
      " [ 2.]\n",
      " [ 3.]]\n"
     ]
    }
   ],
   "source": [
    "W = np.linalg.inv(X_sintetico.T.dot(X_sintetico)).dot(X_sintetico.T).dot(y_sintetico)\n",
    "print(type(W))\n",
    "print(W.shape)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<span style=\"color:blue\">Voy a introducir una fluctuación en los valores de la target para tener un conjunto de datos más realista. Los coeficientes de la regresión lineal, es decir, los pesos se parecerán, pero ya no son exactos.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(50, 1)\n",
      "[[-0.48425667]\n",
      " [-1.1221604 ]\n",
      " [-0.03441665]\n",
      " [ 0.12485512]\n",
      " [ 0.58648096]\n",
      " [ 0.53678654]\n",
      " [ 0.22796723]\n",
      " [ 0.53091137]\n",
      " [ 0.0145445 ]\n",
      " [ 0.76623491]\n",
      " [ 0.22393754]\n",
      " [-0.58784741]\n",
      " [ 0.60957521]\n",
      " [ 0.40420264]\n",
      " [ 0.41687124]\n",
      " [-0.9564608 ]\n",
      " [ 0.24252509]\n",
      " [-0.36286829]\n",
      " [ 0.15175597]\n",
      " [-0.37464867]\n",
      " [ 0.55262101]\n",
      " [ 0.05428347]\n",
      " [ 0.16914359]\n",
      " [ 0.5321433 ]\n",
      " [-0.29146251]\n",
      " [-0.92368245]\n",
      " [ 0.22980425]\n",
      " [-0.10894713]\n",
      " [ 0.51726502]\n",
      " [ 0.37237703]\n",
      " [-0.18262395]\n",
      " [ 0.20253773]\n",
      " [-0.40020821]\n",
      " [-0.00955158]\n",
      " [ 0.05702825]\n",
      " [ 0.01679214]\n",
      " [ 0.4844253 ]\n",
      " [-0.02402542]\n",
      " [ 0.4990105 ]\n",
      " [ 0.26753858]\n",
      " [ 0.22219097]\n",
      " [-0.23936978]\n",
      " [-0.66898494]\n",
      " [-0.2534228 ]\n",
      " [ 0.14743442]\n",
      " [ 0.47494455]\n",
      " [-0.08196093]\n",
      " [ 0.12688225]\n",
      " [-0.43563063]\n",
      " [ 0.26952599]]\n"
     ]
    }
   ],
   "source": [
    "fluctuacion = np.random.normal(0,1,(50,1))/2\n",
    "print(type(fluctuacion))\n",
    "print(fluctuacion.shape)\n",
    "print(fluctuacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -14.48425667],\n",
       "       [  -7.1221604 ],\n",
       "       [   1.96558335],\n",
       "       [  10.12485512],\n",
       "       [  18.58648096],\n",
       "       [  26.53678654],\n",
       "       [  34.22796723],\n",
       "       [  42.53091137],\n",
       "       [  50.0145445 ],\n",
       "       [  58.76623491],\n",
       "       [  66.22393754],\n",
       "       [  73.41215259],\n",
       "       [  82.60957521],\n",
       "       [  90.40420264],\n",
       "       [  98.41687124],\n",
       "       [ 105.0435392 ],\n",
       "       [ 114.24252509],\n",
       "       [ 121.63713171],\n",
       "       [ 130.15175597],\n",
       "       [ 137.62535133],\n",
       "       [ 146.55262101],\n",
       "       [ 154.05428347],\n",
       "       [ 162.16914359],\n",
       "       [ 170.5321433 ],\n",
       "       [ 177.70853749],\n",
       "       [ 647.07631755],\n",
       "       [ 653.22980425],\n",
       "       [ 657.89105287],\n",
       "       [ 663.51726502],\n",
       "       [ 668.37237703],\n",
       "       [ 672.81737605],\n",
       "       [ 678.20253773],\n",
       "       [ 682.59979179],\n",
       "       [ 687.99044842],\n",
       "       [ 693.05702825],\n",
       "       [ 698.01679214],\n",
       "       [ 703.4844253 ],\n",
       "       [ 707.97597458],\n",
       "       [ 713.4990105 ],\n",
       "       [ 718.26753858],\n",
       "       [ 723.22219097],\n",
       "       [ 727.76063022],\n",
       "       [ 732.33101506],\n",
       "       [ 737.7465772 ],\n",
       "       [ 743.14743442],\n",
       "       [ 748.47494455],\n",
       "       [ 752.91803907],\n",
       "       [ 758.12688225],\n",
       "       [ 762.56436937],\n",
       "       [ 768.26952599]])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sintetico = 2*x1_sintetico + 3*x2_sintetico - 4 + fluctuacion\n",
    "y_sintetico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3, 1)\n",
      "[[-3.97355693]\n",
      " [ 2.00535035]\n",
      " [ 2.99902521]]\n"
     ]
    }
   ],
   "source": [
    "W = np.linalg.inv(X_sintetico.T.dot(X_sintetico)).dot(X_sintetico.T).dot(y_sintetico)\n",
    "print(type(W))\n",
    "print(W.shape)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<span style=\"color:blue\">Voy a exportar el conjunto de datos para usarlos en Excel con las expresiones de los pesos deducidas previamente. Compruebo que los valores de los pesos coinciden a la perfección con ambas maneras que he seguido para deducir $W$ (véase el anexo). </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salida = pd.DataFrame(np.concatenate((x1_sintetico,x2_sintetico,y_sintetico),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "salida.to_csv('RegresionLinealPrueba2Features.csv', index=False, header=False) # header = False para que no escriba los nombres\n",
    "                                                                               # de las columnas en la primera fila."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">El ejemplo lineal visto aquí es muy sencillo, pero si la función de activación de la neurona de salida fuera más complicada, como por ejemplo una sigmoide, ya no se podrían aplicar las soluciones analíticas mostradas antes, sino que se utiliza la regla delta. Ya se ha visto que la función de error global es  \n",
    "\\begin{equation}E=\\frac{1}{N}\\sum_{i=1}^N\\frac{1}{2}\\left[y_i-f(\\mathbf{x_i;w})\\right]^2=\\frac{1}{N}\\sum_{i=1}^N\\frac{1}{2}\\left(y_i-\\sum_{a=0}^m w_a x_{ia}\\right)^2=\\frac{1}{N}\\sum_{i=1}^N \\frac{1}{2}\\epsilon_i^2.\\end{equation}  \n",
    "Donde $\\epsilon_i$ es el error individual de un solo patrón de muestra. Lo que hace la regla delta es asignar a cada neurona una modificación de su peso que es proporcional a la variación del error individual respecto al cambio del peso de dicha neurona. Esto puede interpretarse como que este algoritmo modifica el peso de una neurona proporcionalmente a la contribución de dicha neurona al error total. Es decir, las modificaciones en los pesos son proporcionales al gradiente decreciente del error:  \n",
    "\\begin{equation}\\Delta w_b = -\\alpha\\frac{1}{2}\\frac{\\partial\\epsilon_i^2}{\\partial w_b}=-\\alpha\\frac{1}{2}\\cdot 2\\left(y_i-\\sum_{a=0}^m w_a x_{ia}\\right)\\cdot (-x_{ib})=\\alpha(y_i-f(\\mathbf{x_i;w}))x_{ib}=\\alpha\\epsilon_ix_{ib}.\\end{equation}  \n",
    "En notación vectorial:  \n",
    "\\begin{equation}\\mathbf{w}(t+1)=\\mathbf{w}(t)+\\alpha(t)\\epsilon(t)\\mathbf{x}(t).\\end{equation}  \n",
    "Donde $\\alpha$ es la constante de proporcionalidad o tasa de aprendizaje. Esta expresión es parecida a la obtenida anteriormente para el caso del perceptrón. La diferencia está en el valor del error $\\epsilon_i,$ que en el caso del perceptrón se refería a la diferencia entre el valor deseado y la salida binaria $y_i,$ no a la salida lineal de la red ADALINE.  \n",
    "Aunque a simple vista no parece que exista gran diferencia entre ambos tipos de mecanismos de aprendizaje, el caso de la red ADALINE mejora al del perceptrón porque va a ser más sencillo alcanzar el mínimo de error, facilitando la convergencia del proceso de entrenamiento. Esto se demuestra mediante la forma de la función de error, que en el caso de ADALINE tiene forma de paraboloide con un mínimo global claro, mientras que en el caso de usar la salida binaria tiene gran cantidad de mínimos locales. Existe una situación intermedia que consiste en usar una activación sigmoidal. En este caso la superficie de error tendría un gran mínimo global  (como en ADALINE) y varios mínimos locales (como en el perceptrón, pero en menor medida).  \n",
    "La aplicación del algoritmo iterativo de aprendizaje consta de los siguientes pasos:  \n",
    "1. Se inicializan los pesos de la red.\n",
    "2. Se aplica un patrón de entrada, $\\mathbf{x}(t),$ en las neuronas de entrada de la red ADALINE.  \n",
    "3. Se obtiene la salida lineal $\\mathbf{x}(t)\\cdot \\mathbf{w}(t)$ y se calcula la diferencia con respecto a la deseada, $\\epsilon(t).$  \n",
    "4. Se actualizan los pesos, $\\mathbf{w}(t+1)=\\mathbf{w}(t)+\\alpha(t)\\epsilon(t)\\mathbf{x}(t).$  \n",
    "5. Se repiten los pasos anteriores desde el paso 2 con todos los patrones de entrada (N).  \n",
    "6. Si el error cuadrático medio, $\\frac{1}{2N}\\sum_{i=1}^N \\epsilon_i^2,$ es un valor reducido aceptable, termina el proceso de aprendizaje. Si no, se repite otra vez desde el primer paso con todos los patrones.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<span style=\"color:blue\">Paso ahora a montar una red ADALINE con activación identidad usando keras y le aplico el conjunto de datos anterior para comprobar que los pesos que obtiene mediante una variante de algoritmo de gradiente decreciente coinciden con los de la regresión lineal que acabo de hacer de dos maneras analíticas exactas.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -4],\n",
       "       [ 2, -2],\n",
       "       [ 3,  0],\n",
       "       [ 4,  2]])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sintetico = np.concatenate((x1_sintetico,x2_sintetico),axis=1)\n",
    "x_sintetico[:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras import backend as K\n",
    "\n",
    "def identidad(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_144 (Dense)                (None, 1)             3           dense_input_129[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_143 (Activation)      (None, 1)             0           dense_144[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/80\n",
      "3s - loss: 26426.2108\n",
      "Epoch 2/80\n",
      "0s - loss: 11088.9977\n",
      "Epoch 3/80\n",
      "0s - loss: 2708.9644\n",
      "Epoch 4/80\n",
      "0s - loss: 742.7583\n",
      "Epoch 5/80\n",
      "0s - loss: 195.0173\n",
      "Epoch 6/80\n",
      "0s - loss: 154.2536\n",
      "Epoch 7/80\n",
      "0s - loss: 228.9606\n",
      "Epoch 8/80\n",
      "0s - loss: 301.6581\n",
      "Epoch 9/80\n",
      "0s - loss: 296.6746\n",
      "Epoch 10/80\n",
      "0s - loss: 259.4959\n",
      "Epoch 11/80\n",
      "0s - loss: 185.4533\n",
      "Epoch 12/80\n",
      "0s - loss: 119.3788\n",
      "Epoch 13/80\n",
      "0s - loss: 41.5657\n",
      "Epoch 14/80\n",
      "0s - loss: 10.3057\n",
      "Epoch 15/80\n",
      "0s - loss: 3.7200\n",
      "Epoch 16/80\n",
      "0s - loss: 3.8202\n",
      "Epoch 17/80\n",
      "0s - loss: 9.6919\n",
      "Epoch 18/80\n",
      "0s - loss: 4.6301\n",
      "Epoch 19/80\n",
      "0s - loss: 1.5858\n",
      "Epoch 20/80\n",
      "0s - loss: 1.2303\n",
      "Epoch 21/80\n",
      "0s - loss: 1.2133\n",
      "Epoch 22/80\n",
      "0s - loss: 0.7481\n",
      "Epoch 23/80\n",
      "0s - loss: 1.5032\n",
      "Epoch 24/80\n",
      "0s - loss: 0.5178\n",
      "Epoch 25/80\n",
      "0s - loss: 0.9566\n",
      "Epoch 26/80\n",
      "0s - loss: 1.1106\n",
      "Epoch 27/80\n",
      "0s - loss: 0.5969\n",
      "Epoch 28/80\n",
      "0s - loss: 0.6863\n",
      "Epoch 29/80\n",
      "0s - loss: 0.4703\n",
      "Epoch 30/80\n",
      "0s - loss: 0.4201\n",
      "Epoch 31/80\n",
      "0s - loss: 0.4353\n",
      "Epoch 32/80\n",
      "0s - loss: 0.3527\n",
      "Epoch 33/80\n",
      "0s - loss: 0.7375\n",
      "Epoch 34/80\n",
      "0s - loss: 0.9473\n",
      "Epoch 35/80\n",
      "0s - loss: 0.4803\n",
      "Epoch 36/80\n",
      "0s - loss: 0.3978\n",
      "Epoch 37/80\n",
      "0s - loss: 1.0374\n",
      "Epoch 38/80\n",
      "0s - loss: 0.6436\n",
      "Epoch 39/80\n",
      "0s - loss: 0.6710\n",
      "Epoch 40/80\n",
      "0s - loss: 1.2724\n",
      "Epoch 41/80\n",
      "0s - loss: 1.4941\n",
      "Epoch 42/80\n",
      "0s - loss: 3.0697\n",
      "Epoch 43/80\n",
      "0s - loss: 1.4735\n",
      "Epoch 44/80\n",
      "0s - loss: 0.5777\n",
      "Epoch 45/80\n",
      "0s - loss: 0.4962\n",
      "Epoch 46/80\n",
      "0s - loss: 0.3459\n",
      "Epoch 47/80\n",
      "0s - loss: 0.9537\n",
      "Epoch 48/80\n",
      "0s - loss: 3.8053\n",
      "Epoch 49/80\n",
      "0s - loss: 0.9220\n",
      "Epoch 50/80\n",
      "0s - loss: 0.3264\n",
      "Epoch 51/80\n",
      "0s - loss: 0.2677\n",
      "Epoch 52/80\n",
      "0s - loss: 0.2883\n",
      "Epoch 53/80\n",
      "0s - loss: 0.2667\n",
      "Epoch 54/80\n",
      "0s - loss: 0.3293\n",
      "Epoch 55/80\n",
      "0s - loss: 0.3337\n",
      "Epoch 56/80\n",
      "0s - loss: 0.7967\n",
      "Epoch 57/80\n",
      "0s - loss: 0.6647\n",
      "Epoch 58/80\n",
      "0s - loss: 0.3625\n",
      "Epoch 59/80\n",
      "0s - loss: 0.3302\n",
      "Epoch 60/80\n",
      "0s - loss: 0.2324\n",
      "Epoch 61/80\n",
      "0s - loss: 0.2367\n",
      "Epoch 62/80\n",
      "0s - loss: 0.2595\n",
      "Epoch 63/80\n",
      "0s - loss: 0.6482\n",
      "Epoch 64/80\n",
      "0s - loss: 0.2150\n",
      "Epoch 65/80\n",
      "0s - loss: 0.3431\n",
      "Epoch 66/80\n",
      "0s - loss: 0.8565\n",
      "Epoch 67/80\n",
      "0s - loss: 0.3572\n",
      "Epoch 68/80\n",
      "0s - loss: 0.2546\n",
      "Epoch 69/80\n",
      "0s - loss: 0.3887\n",
      "Epoch 70/80\n",
      "0s - loss: 0.7018\n",
      "Epoch 71/80\n",
      "0s - loss: 0.5852\n",
      "Epoch 72/80\n",
      "0s - loss: 0.2118\n",
      "Epoch 73/80\n",
      "0s - loss: 0.3307\n",
      "Epoch 74/80\n",
      "0s - loss: 0.2417\n",
      "Epoch 75/80\n",
      "0s - loss: 0.2594\n",
      "Epoch 76/80\n",
      "0s - loss: 0.3780\n",
      "Epoch 77/80\n",
      "0s - loss: 0.7785\n",
      "Epoch 78/80\n",
      "0s - loss: 0.2562\n",
      "Epoch 79/80\n",
      "0s - loss: 0.2125\n",
      "Epoch 80/80\n",
      "0s - loss: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x538c0780>"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaline=Sequential()\n",
    "adaline.add(Dense(1, input_shape=(2,),activation=identidad))\n",
    "adaline.add(Activation(identidad))\n",
    "\n",
    "adaline.summary()\n",
    "\n",
    "adam = Adam(lr=1.5,decay=0.0005685)\n",
    "adaline.compile(loss='mean_squared_error',\n",
    "               optimizer=adam)\n",
    "               # metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    \n",
    "adaline.fit(x_sintetico, y_sintetico, batch_size=5, # Batch size for the optimizer algorithm\n",
    "    nb_epoch=80, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    "    #WeightLogger()\n",
    "    #callbacks=[history]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.00519991],\n",
       "        [ 2.99923468]], dtype=float32), array([-3.97315216], dtype=float32)]"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaline.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Efectivamente, los pesos a los que llega la red después del proceso de aprendizaje son justamente los coeficientes de la regresión lineal obtenidos previamente ($w_0=-3.973, w_1=2.005$ y $w_2=2.999$). Por tanto, queda comprobado el funcionamiento de una red ADALINE como regresor lineal.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Red backpropagation</span>\n",
    "\n",
    "<span style=\"color:blue\">Ahora paso a considerar redes con capas ocultas, es decir, con más niveles de neuronas que los empleados por el perceptrón y ADALINE. El método de aprendizaje que se va a utilizar se conoce generalmente como *backpropagation* y está basado en la regla delta. Este método consta de dos fases. Primero se aplica un patrón de entrada, que se va propagando a través de todas las capas superiores hasta generar una salida, que se compara con la salida deseada, y se calcula un error para cada neurona de salida. A continuación, estos errores se transmiten hacia atrás, partiendo de la capa de salida hacia todas las neuronas de la capa intermedia que contribuyen directamente a la salida, recibiendo el porcentaje de error aproximado a la participación de la neurona intermedia en la salida original. Este proceso se repite capa por capa hasta que todas las neuronas de la red hayan recibido un error que describa su aportación relativa al error total. Basándose en el valor del error recibido, se reajustan los pesos de cada neurona, de forma que la siguiente vez que se presente el mismo patrón, la salida esté más cercana a la deseada, es decir, el error disminuya.  \n",
    "Este método sigue la regla delta generalizada. Los pesos se ajustan como en la regla delta usada en el perceptrón y ADALINE: los pesos se actualizan de forma proporcional a la delta o diferencia entre la salida deseada y la obtenida. El punto en el que difieren la regla delta generalizada de la regla delta es en el valor concreto de esa delta. Además, en las redes multinivel, al contrario que en las redes sin neuronas ocultas, no se puede conocer en principio la salida deseada de las neuronas de las capas ocultas para poder determinar los pesos en función del error cometido. En cambio, sí se puede conocer la salida deseada de las neuronas de salida. Voy a suponer una red con una capa oculta.\n",
    "El algoritmo consta de los siguientes pasos:\n",
    "1. Se inicializan los pesos de la red.\n",
    "2. Se aplica un patrón de entrada, $\\mathbf{x}(t),$ en las neuronas de entrada de la red.  \n",
    "3. Se calculan las entradas a las neuronas ocultas procedentes de las neuronas de entrada, $A_b(t) = \\sum_{a=0}^{m_1} U_{ba}x_a(t),$ donde $U_{ba}$ es el peso de interconexión entre la neurona oculta b-ésima y la neurona de entrada a-ésima, $m_1$ es el número de unidades de la capa de entrada y $x_a(t)$ es la feature a-ésima, es decir, la componente a-esima del patrón de entrada.  \n",
    "4. Se calculan las salidas de las neuronas ocultas, $O_b(t)=\\sigma(A_b(t)).$  \n",
    "5. Se calculan las entradas a las neuronas de salida procedentes de las neuronas ocultas, $z_c(t) = \\sum_{b=0}^{m_2} V_{cb}O_b(t),$ donde $V_{cb}$ es el peso de interconexión entre la neurona de salida c-ésima y la neurona oculta b-ésima, $m_2$ es el número de unidades de la capa oculta. Los subíndices $a, b, c$ hacen referencia a las neuronas de las capas de entrada, oculta y de salida, respectivamente.  \n",
    "6. Se calculan las salidas de las neuronas de salida, $\\phi(z_c(t)).$\n",
    "7. Se actualizan los pesos: \n",
    "\\begin{eqnarray} V_{cb}(t+1)&=& V_{cb}(t)+\\alpha(t)\\epsilon_c(t)O_b(t), \\;\\;\\; \\mbox{ donde  }\\; \\epsilon_c(t)=[y_c(t)-\\phi(z_c(t))]\\phi'(z_c(t)) \\\\\n",
    "U_{ba}(t+1)&=& U_{ba}(t)+\\alpha(t)\\delta_b(t)x_a(t), \\;\\;\\; \\mbox{ donde  }\\; \\delta_b(t)=\\sigma'(A_b(t))\\sum_{c=0}^{m_3}V_{cb}(t)\\epsilon_c(t).  \\end{eqnarray}  \n",
    "Siendo $y_c(t)$ la salida deseada de la neurona de salida c-ésima para el patrón presentado en el instante $t.$  \n",
    "En el caso de que la función de activación de la capa de salida fuera la identidad, $\\phi(z)=z,$ se tendría $\\phi'(z)=1$ y los términos de error para las neuronas de salida quedan $\\epsilon_c(t)=y_c(t)-\\phi(z_c(t)).$ Si la función de activación de la capa de salida fuera sigmoidal, $\\phi(z)=1/(1+e^{-z}),$ se tendría $\\phi'(z)=\\phi(z)(1-\\phi(z)).$  \n",
    "Nótese que el error de las capas ocultas, $\\delta_b,$ depende de todos los términos de error de la capa de salida, $\\epsilon_c.$ De aquí surge la nomenclatura de *backpropagation*. Los errores de una capa dependen de los errores de la capa inmediatamente posterior.\n",
    "8. Se repiten los pasos anteriores desde el paso 2 hasta que el error resulta aceptablemente pequeño.   \n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">Una vez vista esta introducción paso a la práctica propiamente dicha.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Keras library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will make use of the <a href=http://keras.io/>keras</a> Deep Learning library for Python. This library allows building several kinds of shallow and deep networks, following either a sequential or a graph architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The handwritten digits recognition problem we will face is already included as a testbed in keras. Loading it only requires invoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.pkl.gz\n",
      "15302656/15296311 [==============================] - 8s     \n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded **X** variables are made up of the handwritten digits to classify, while the **y** variables contain the labels of the corresponding X images, telling the digits such images represent. We will use the **train** data to build our neural network, while we will use the **test** data to measure the performance of such network on an independent dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how many images we have for training and testing as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(type(X_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can take a look at the shape, width and height in pixels, of an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01176471,  0.07058824,  0.07058824,\n",
       "        0.07058824,  0.49411765,  0.53333336,  0.68627453,  0.10196079,\n",
       "        0.65098041,  1.        ,  0.96862745,  0.49803922,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the images we are working with by means of using the matplotlib library. Here we are taking the first training image and painting it with a grayscale colormap. Also we are printing the corresponding class value, to ensure the labeling of the digit is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit class: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa25d748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], 'gray')\n",
    "print(\"Digit class:\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Use the cell below to plot some other image in the training dataset, along with its corresponding digit class number. Can you find any hard to identify digit?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit class: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKGFCCKkRSpgQQmqEEiaEkBr5/7sFctEUr5qDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f65e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "plt.imshow(X_train[240], 'gray')\n",
    "print(\"Digit class:\", y_train[240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit class: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18fbe080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[5000], 'coolwarm')\n",
    "print(\"Digit class:\", y_train[5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting building networks we should always normalize our data. This usually means substracting the mean from each variable and then dividing by the standard deviation. However in grayscale images like the ones we are working with all variables represent pixel intensities, and are bound to integers in the range [0, 255]. We can thus perform a simple initialization by just compressing this range to [0, 1]. We should also transform the data to real numbers (float) while performing this operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Perform the same normalization for the test data\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the outputs, normalization as such is not required, but we should change the class encoding to something more akin to neural networks. Instead of having a single integer ranging [0,9] to encode the different classes, we will use a <a href=https://en.wikipedia.org/wiki/One-hot>one-hot vector encoding</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(y_train, 10) # We have 10 classes to codify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the transformation was correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Repeat the same encoding for the classes of the test data\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start trying to solve the problem with the simplest neural network: a Perceptron. This means a neural network with no hidden layers, just some weights going from input to output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a network in Keras begins by choosing the type of architecture. We can either decide to build a **Sequential** network, where each layer is followed by another one in a chain, or a **Graph** network, where divergences and loops of layers can take place. In this practice we will restrict ourselves to the Sequential architecture. We can initialize a Sequential network with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the network has been initialized this way, we just need to iteratively add the desired layers. For the perceptron network we only require a \"classic\" layer of weights from input to output. Such layer is name **Dense** in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually creating a dense layer only involves specifying the number of outputs units of such layer. But since this will be the first layer in the network we also need to specify the number of inputs. Our inputs are images of 28x28 pixels, which makes 784 input values. As for the outputs, we have 10 classes in our problem, so that makes 10 output units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "denselayer = Dense(10, input_shape=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add the layer to network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(denselayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we have declared the layer of weights from inputs to outputs. Since we are facing a classification problem we should also add an activation function to the output units that enforces the output values to the range [0,1]. We will choose a softmax activation for doing so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Activation\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this the definition of our network is completed. We can get a text description of the network by calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 10)            7850        dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 10)            0           dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the network architecture the next step involves compiling the network. Compilation is an automatic process that transforms the network definition into an equivalent symbolic formulation for which derivatives can be computed, thus allowing learning through backpropagation. The only input required in this process is choosing the loss function the network should minimize, and the optimizer used for learning.\n",
    "\n",
    "For our current network we will use **categorical crossentropy** as the loss function, as it is suitable for multiclass classification problems. As for the optimizer, we will use **Stochastic Gradient Descent**. We will also include the **classification accuracy** as a metric to measure the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now almost ready to adjust the network parameters through training over our data. There is only one small detail left: our data is in the form of bidimensional images, while a perceptron only understands training patterns as one-dimensional vectors of data. We should then transform the data to vector form to input it into the network, something we can do with the **reshape** method of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainvectors = X_train.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check now that our training data has become a matrix of 60000 training patterns (rows) and 784 variables (pixels) per pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainvectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Compruebo que, por ejemplo, las componentes de la quinta fila de la primera imagen (posición 0), X_train[0][5], son las mismas. Cada fila contiene 28 elementos (28 columnas), así que tengo que comprobar desde la posición 5x28=140 hasta la 140+28=168, trainvectors[0][140:168]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01176471,  0.07058824,  0.07058824,\n",
       "        0.07058824,  0.49411765,  0.53333336,  0.68627453,  0.10196079,\n",
       "        0.65098041,  1.        ,  0.96862745,  0.49803922,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainvectors[0][140:168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01176471,  0.07058824,  0.07058824,\n",
       "        0.07058824,  0.49411765,  0.53333336,  0.68627453,  0.10196079,\n",
       "        0.65098041,  1.        ,  0.96862745,  0.49803922,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Perform a similar transformation for the X_test data, saving the reshaped data into a variable named *testvectors*. Note that the number of pattens in the test data is different from the number of patterns in the training data.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "testvectors = X_test.reshape(10000,784)\n",
    "testvectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can invoke the **fit** method of the network, which will perform the training process. It is done as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5s - loss: 1.2713 - acc: 0.7070\n",
      "Epoch 2/20\n",
      "4s - loss: 0.7116 - acc: 0.8410\n",
      "Epoch 3/20\n",
      "4s - loss: 0.5840 - acc: 0.8596\n",
      "Epoch 4/20\n",
      "4s - loss: 0.5226 - acc: 0.8692\n",
      "Epoch 5/20\n",
      "4s - loss: 0.4852 - acc: 0.8759\n",
      "Epoch 6/20\n",
      "4s - loss: 0.4595 - acc: 0.8798\n",
      "Epoch 7/20\n",
      "4s - loss: 0.4405 - acc: 0.8840\n",
      "Epoch 8/20\n",
      "4s - loss: 0.4257 - acc: 0.8867\n",
      "Epoch 9/20\n",
      "4s - loss: 0.4137 - acc: 0.8894\n",
      "Epoch 10/20\n",
      "4s - loss: 0.4039 - acc: 0.8914\n",
      "Epoch 11/20\n",
      "4s - loss: 0.3955 - acc: 0.8933\n",
      "Epoch 12/20\n",
      "4s - loss: 0.3883 - acc: 0.8948\n",
      "Epoch 13/20\n",
      "4s - loss: 0.3820 - acc: 0.8957\n",
      "Epoch 14/20\n",
      "4s - loss: 0.3764 - acc: 0.8969\n",
      "Epoch 15/20\n",
      "4s - loss: 0.3714 - acc: 0.8980\n",
      "Epoch 16/20\n",
      "4s - loss: 0.3669 - acc: 0.8992\n",
      "Epoch 17/20\n",
      "4s - loss: 0.3629 - acc: 0.9003\n",
      "Epoch 18/20\n",
      "4s - loss: 0.3592 - acc: 0.9011\n",
      "Epoch 19/20\n",
      "4s - loss: 0.3559 - acc: 0.9017\n",
      "Epoch 20/20\n",
      "4s - loss: 0.3527 - acc: 0.9027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa3507f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    nb_epoch=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our neural network model is trained, we can obtain class predictions for the test set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s     \n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_classes(testvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for instance, the first image in the test set and its predicted class are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real class 7 predicted class 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCGkRijAhhLQIRZgQQlqEIkwIIS3y/wFYJOCHHvLvRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa555eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0], 'gray')\n",
    "print(\"Real class\", y_test[0], \"predicted class\", preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Compare the predicted and real classes for other images in the test set. Can you find any error?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/exclamation.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "You can spot all the errors in an automated way by comparing *y_test* against *preds* and getting the indexes of the mismatching elements. The function <a href=http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.where.html>np.where</a> might also help.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "1\n",
      "898\n",
      "(array([   8,   33,   46,   63,   77,   92,  111,  124,  149,  193,  195,\n",
      "        217,  233,  241,  243,  245,  247,  259,  290,  300,  307,  313,\n",
      "        318,  320,  321,  325,  340,  341,  352,  362,  403,  435,  444,\n",
      "        445,  448,  449,  464,  468,  478,  479,  483,  495,  502,  507,\n",
      "        511,  515,  530,  531,  536,  543,  551,  553,  565,  569,  578,\n",
      "        582,  591,  605,  610,  613,  619,  624,  627,  628,  629,  638,\n",
      "        658,  659,  684,  691,  707,  717,  720,  728,  738,  740,  741,\n",
      "        760,  781,  791,  795,  800,  839,  844,  857,  881,  882,  898,\n",
      "        900,  924,  938,  939,  944,  947,  950,  956,  959,  965,  975,\n",
      "        982, 1012, 1014, 1032, 1033, 1039, 1044, 1050, 1062, 1068, 1082,\n",
      "       1096, 1101, 1107, 1112, 1114, 1119, 1147, 1173, 1181, 1192, 1194,\n",
      "       1198, 1200, 1202, 1204, 1206, 1208, 1217, 1224, 1226, 1228, 1232,\n",
      "       1233, 1234, 1242, 1247, 1248, 1251, 1256, 1260, 1283, 1289, 1291,\n",
      "       1299, 1319, 1326, 1328, 1337, 1339, 1345, 1347, 1357, 1375, 1378,\n",
      "       1391, 1393, 1402, 1410, 1429, 1433, 1440, 1444, 1453, 1465, 1466,\n",
      "       1467, 1469, 1494, 1500, 1514, 1522, 1525, 1527, 1530, 1549, 1553,\n",
      "       1559, 1581, 1587, 1609, 1634, 1640, 1641, 1678, 1681, 1686, 1695,\n",
      "       1696, 1709, 1716, 1717, 1718, 1722, 1727, 1741, 1751, 1754, 1759,\n",
      "       1765, 1772, 1773, 1774, 1782, 1790, 1800, 1813, 1819, 1828, 1839,\n",
      "       1850, 1857, 1865, 1868, 1874, 1878, 1883, 1899, 1901, 1903, 1911,\n",
      "       1917, 1926, 1930, 1938, 1940, 1948, 1952, 1955, 1956, 1968, 1970,\n",
      "       1973, 1981, 1982, 1984, 1989, 1993, 2016, 2024, 2035, 2040, 2043,\n",
      "       2044, 2053, 2068, 2070, 2093, 2098, 2099, 2105, 2109, 2110, 2115,\n",
      "       2118, 2129, 2130, 2134, 2135, 2138, 2148, 2152, 2168, 2182, 2185,\n",
      "       2186, 2189, 2192, 2208, 2215, 2224, 2266, 2269, 2272, 2282, 2293,\n",
      "       2298, 2299, 2325, 2351, 2362, 2369, 2371, 2380, 2381, 2387, 2393,\n",
      "       2394, 2395, 2397, 2404, 2406, 2408, 2422, 2425, 2433, 2449, 2460,\n",
      "       2488, 2507, 2513, 2525, 2534, 2542, 2556, 2559, 2560, 2573, 2574,\n",
      "       2578, 2586, 2589, 2598, 2604, 2607, 2610, 2631, 2635, 2648, 2654,\n",
      "       2668, 2670, 2695, 2705, 2713, 2740, 2751, 2770, 2771, 2780, 2805,\n",
      "       2810, 2812, 2832, 2850, 2851, 2866, 2896, 2905, 2906, 2907, 2914,\n",
      "       2919, 2925, 2927, 2945, 2953, 2969, 2970, 2990, 2995, 3005, 3060,\n",
      "       3073, 3102, 3106, 3110, 3114, 3117, 3130, 3133, 3136, 3145, 3157,\n",
      "       3160, 3166, 3167, 3176, 3189, 3193, 3206, 3225, 3240, 3269, 3280,\n",
      "       3284, 3288, 3289, 3302, 3316, 3329, 3330, 3333, 3369, 3388, 3394,\n",
      "       3436, 3437, 3448, 3450, 3468, 3475, 3490, 3503, 3520, 3525, 3549,\n",
      "       3558, 3565, 3567, 3573, 3578, 3580, 3597, 3598, 3604, 3629, 3645,\n",
      "       3662, 3664, 3681, 3688, 3716, 3718, 3726, 3727, 3730, 3732, 3751,\n",
      "       3752, 3757, 3763, 3767, 3769, 3776, 3780, 3794, 3796, 3801, 3806,\n",
      "       3808, 3811, 3817, 3820, 3821, 3833, 3836, 3838, 3839, 3846, 3848,\n",
      "       3850, 3853, 3855, 3862, 3869, 3876, 3884, 3893, 3902, 3906, 3926,\n",
      "       3929, 3941, 3943, 3946, 3951, 3952, 3954, 3962, 3965, 3976, 3984,\n",
      "       3985, 4000, 4002, 4017, 4044, 4059, 4063, 4065, 4072, 4075, 4076,\n",
      "       4078, 4093, 4111, 4131, 4140, 4145, 4152, 4154, 4156, 4159, 4163,\n",
      "       4173, 4176, 4177, 4180, 4199, 4201, 4205, 4211, 4212, 4224, 4238,\n",
      "       4239, 4248, 4254, 4256, 4265, 4271, 4284, 4289, 4297, 4300, 4302,\n",
      "       4306, 4313, 4315, 4317, 4330, 4341, 4344, 4355, 4356, 4359, 4369,\n",
      "       4374, 4405, 4423, 4427, 4433, 4435, 4449, 4451, 4454, 4477, 4497,\n",
      "       4498, 4500, 4521, 4523, 4540, 4567, 4571, 4575, 4578, 4583, 4601,\n",
      "       4615, 4639, 4640, 4671, 4722, 4724, 4731, 4735, 4740, 4743, 4751,\n",
      "       4761, 4785, 4807, 4808, 4812, 4814, 4823, 4827, 4829, 4837, 4838,\n",
      "       4863, 4874, 4876, 4879, 4880, 4886, 4888, 4890, 4896, 4910, 4915,\n",
      "       4939, 4943, 4950, 4952, 4954, 4956, 4966, 4968, 4978, 4990, 5001,\n",
      "       5009, 5015, 5038, 5046, 5054, 5065, 5067, 5068, 5078, 5086, 5100,\n",
      "       5135, 5138, 5140, 5143, 5177, 5210, 5217, 5246, 5278, 5288, 5298,\n",
      "       5331, 5457, 5523, 5562, 5600, 5611, 5617, 5620, 5634, 5642, 5649,\n",
      "       5653, 5662, 5677, 5678, 5688, 5714, 5734, 5735, 5749, 5821, 5835,\n",
      "       5852, 5862, 5867, 5874, 5887, 5888, 5891, 5912, 5913, 5922, 5936,\n",
      "       5937, 5955, 5972, 5973, 5975, 5985, 6004, 6023, 6024, 6035, 6037,\n",
      "       6042, 6043, 6059, 6065, 6071, 6081, 6091, 6109, 6112, 6124, 6157,\n",
      "       6166, 6168, 6172, 6173, 6174, 6304, 6324, 6347, 6385, 6391, 6392,\n",
      "       6400, 6421, 6425, 6426, 6432, 6480, 6494, 6501, 6505, 6517, 6555,\n",
      "       6560, 6568, 6569, 6574, 6577, 6597, 6598, 6603, 6625, 6632, 6641,\n",
      "       6642, 6651, 6657, 6661, 6688, 6694, 6706, 6721, 6740, 6744, 6746,\n",
      "       6768, 6769, 6775, 6785, 6796, 6847, 6885, 6906, 6909, 6919, 6926,\n",
      "       7035, 7043, 7094, 7107, 7121, 7130, 7212, 7216, 7220, 7235, 7241,\n",
      "       7262, 7265, 7304, 7338, 7394, 7432, 7434, 7436, 7451, 7454, 7459,\n",
      "       7472, 7473, 7492, 7498, 7511, 7542, 7580, 7603, 7637, 7641, 7672,\n",
      "       7724, 7797, 7800, 7821, 7826, 7839, 7842, 7847, 7849, 7850, 7856,\n",
      "       7857, 7858, 7859, 7870, 7876, 7886, 7888, 7899, 7900, 7905, 7917,\n",
      "       7918, 7920, 7928, 7945, 8020, 8047, 8062, 8072, 8081, 8091, 8094,\n",
      "       8095, 8165, 8183, 8196, 8198, 8246, 8272, 8277, 8279, 8294, 8308,\n",
      "       8332, 8339, 8353, 8408, 8410, 8426, 8444, 8476, 8520, 8522, 8553,\n",
      "       8639, 9006, 9007, 9009, 9010, 9013, 9015, 9017, 9019, 9024, 9026,\n",
      "       9036, 9045, 9071, 9110, 9141, 9168, 9209, 9211, 9214, 9245, 9280,\n",
      "       9316, 9317, 9426, 9446, 9456, 9465, 9482, 9534, 9544, 9554, 9560,\n",
      "       9587, 9595, 9614, 9624, 9634, 9642, 9643, 9662, 9664, 9679, 9680,\n",
      "       9700, 9712, 9716, 9719, 9726, 9729, 9732, 9733, 9735, 9740, 9741,\n",
      "       9744, 9745, 9749, 9751, 9752, 9764, 9768, 9770, 9777, 9779, 9780,\n",
      "       9792, 9808, 9811, 9832, 9839, 9840, 9847, 9855, 9856, 9858, 9867,\n",
      "       9874, 9879, 9883, 9888, 9890, 9893, 9905, 9925, 9940, 9941, 9943,\n",
      "       9944, 9959, 9970, 9975, 9980, 9982, 9986], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "import numpy as np\n",
    "erroneos = np.where(y_test!=preds)\n",
    "print(type(erroneos))\n",
    "print(len(erroneos))\n",
    "print(len(erroneos[0]))\n",
    "print(erroneos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real class 5 predicted class 5 True\n",
      "Real class 9 predicted class 8 False\n",
      "Real class 8 predicted class 8 True\n",
      "Real class 7 predicted class 4 False\n",
      "Real class 2 predicted class 2 True\n",
      "Real class 3 predicted class 6 False\n",
      "Real class 0 predicted class 0 True\n",
      "Real class 4 predicted class 2 False\n",
      "Real class 4 predicted class 4 True\n",
      "Real class 2 predicted class 2 True\n",
      "\n",
      "Real class 9 predicted class 8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYToEImwEEJ0iERYCCE6RCIshBAd8v8D1kzU8ZTSg6kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f829b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[print(\"Real class\", y_test[n], \"predicted class\", preds[n], y_test[n]==preds[n] ) for n in range (240,250)]\n",
    "print(\"\")\n",
    "plt.imshow(X_test[241], 'gray')\n",
    "print(\"Real class\", y_test[241], \"predicted class\", preds[241])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overall accuracy measure can also be obtained by means of the **evaluate** method of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s     \n",
      "Test loss 0.334776274955\n",
      "Test accuracy 0.9102\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(testvectors, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Do you think the level of accuracy obtained is good enough for a real application? Consider that every time a digit is misclasified a package might be sent to the wrong address and, ZIP codes in the USA include up to 9 digits.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Sea el suceso $A = \\{\\mbox{acertar un dígito}\\}$. Se puede considerar que la probabilidad de que ocurra el suceso $A$ es la *accuracy* lograda por el perceptrón, es decir, $p(A) = 0,9102.$ Sea un código postal de Estados Unidos de 9 dígitos. Esto equivale a realizar el experimento 9 veces. Asumiendo que la probabilidad de acertar un dígito no influye en la de acertar los demás (sucesos independientes), la probabilidad de acertar correctamente el código postal es $p(A\\cap A\\cap\\stackrel{(9}{\\ldots}\\cap A)= p^9 = 0,9102^9 = 0,4288,$ que es bastante baja. Habría muchísimos errores en los envíos postales. Es necesario reducir la *accuracy* en test.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potential way to attain further improvements might be to create a deeper network, by adding layers of hidden units. This is easy to do in Keras, just by defining a new architecture with several Dense layers. For example, to build a network with a hidden layer of 10 units with sigmoid activation we would write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(10, input_shape=(784,)))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_4 (Dense)                  (None, 10)            7850        dense_input_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 10)            0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 10)            110         activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 10)            0           dense_5[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 7,960\n",
      "Trainable params: 7,960\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Compile the defined network and train it with the data. Then measure the accuracy over the test data. Have you managed to get any improvement over the previous Perceptron model?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5s - loss: 2.1887 - acc: 0.3298\n",
      "Epoch 2/20\n",
      "4s - loss: 1.9605 - acc: 0.5696\n",
      "Epoch 3/20\n",
      "4s - loss: 1.7685 - acc: 0.6206\n",
      "Epoch 4/20\n",
      "4s - loss: 1.5972 - acc: 0.6521\n",
      "Epoch 5/20\n",
      "4s - loss: 1.4469 - acc: 0.6839\n",
      "Epoch 6/20\n",
      "4s - loss: 1.3168 - acc: 0.7130\n",
      "Epoch 7/20\n",
      "4s - loss: 1.2050 - acc: 0.7391\n",
      "Epoch 8/20\n",
      "4s - loss: 1.1098 - acc: 0.7633\n",
      "Epoch 9/20\n",
      "4s - loss: 1.0289 - acc: 0.7831\n",
      "Epoch 10/20\n",
      "4s - loss: 0.9603 - acc: 0.7979\n",
      "Epoch 11/20\n",
      "4s - loss: 0.9020 - acc: 0.8097\n",
      "Epoch 12/20\n",
      "4s - loss: 0.8522 - acc: 0.8197\n",
      "Epoch 13/20\n",
      "4s - loss: 0.8093 - acc: 0.8267\n",
      "Epoch 14/20\n",
      "5s - loss: 0.7722 - acc: 0.8323\n",
      "Epoch 15/20\n",
      "4s - loss: 0.7398 - acc: 0.8377\n",
      "Epoch 16/20\n",
      "4s - loss: 0.7112 - acc: 0.8422\n",
      "Epoch 17/20\n",
      "4s - loss: 0.6859 - acc: 0.8456\n",
      "Epoch 18/20\n",
      "4s - loss: 0.6633 - acc: 0.8490\n",
      "Epoch 19/20\n",
      "4s - loss: 0.6431 - acc: 0.8519\n",
      "Epoch 20/20\n",
      "4s - loss: 0.6247 - acc: 0.8544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6cd6f60>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    nb_epoch=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "preds2 = model2.predict_classes(testvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1436\n"
     ]
    }
   ],
   "source": [
    "erroneos2 = np.where(y_test!=preds2)\n",
    "print(len(erroneos2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s\n",
      "Test loss 0.603597908306\n",
      "Test accuracy 0.8564\n"
     ]
    }
   ],
   "source": [
    "score2 = model2.evaluate(testvectors, Y_test)\n",
    "print(\"\")\n",
    "print(\"Test loss\", score2[0])\n",
    "print(\"Test accuracy\", score2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">No solo no ha mejorado la precisión sino que ha disminuido sensiblemente.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the network design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the performance of the multilayer perceptron we will use the following:\n",
    "* Increase the number of hidden units\n",
    "* Use a better activation function: rectified linear\n",
    "* Use a better optimizer: adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This boils down to defining the network as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(100, input_shape=(784,)))  # Aumentamos a 100 las unidades de la capa escondida.\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dense(10))                 # La capa de salida corresponde a diez categorías.\n",
    "model3.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Compile the defined network, choosing \"adam\" as the optimization algorithm, and train it with the data. Then measure the accuracy over the test data. Did these changes give rise to better results?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11s - loss: 0.3693 - acc: 0.9001\n",
      "Epoch 2/20\n",
      "11s - loss: 0.1708 - acc: 0.9518\n",
      "Epoch 3/20\n",
      "9s - loss: 0.1239 - acc: 0.9650\n",
      "Epoch 4/20\n",
      "9s - loss: 0.0979 - acc: 0.9718\n",
      "Epoch 5/20\n",
      "9s - loss: 0.0790 - acc: 0.9774\n",
      "Epoch 6/20\n",
      "9s - loss: 0.0663 - acc: 0.9808\n",
      "Epoch 7/20\n",
      "9s - loss: 0.0560 - acc: 0.9848\n",
      "Epoch 8/20\n",
      "9s - loss: 0.0485 - acc: 0.9857\n",
      "Epoch 9/20\n",
      "9s - loss: 0.0410 - acc: 0.9886\n",
      "Epoch 10/20\n",
      "9s - loss: 0.0357 - acc: 0.9906\n",
      "Epoch 11/20\n",
      "9s - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 12/20\n",
      "9s - loss: 0.0260 - acc: 0.9931\n",
      "Epoch 13/20\n",
      "9s - loss: 0.0230 - acc: 0.9940\n",
      "Epoch 14/20\n",
      "9s - loss: 0.0198 - acc: 0.9952\n",
      "Epoch 15/20\n",
      "9s - loss: 0.0164 - acc: 0.9964\n",
      "Epoch 16/20\n",
      "9s - loss: 0.0147 - acc: 0.9967\n",
      "Epoch 17/20\n",
      "9s - loss: 0.0129 - acc: 0.9971\n",
      "Epoch 18/20\n",
      "9s - loss: 0.0107 - acc: 0.9978\n",
      "Epoch 19/20\n",
      "9s - loss: 0.0094 - acc: 0.9981\n",
      "Epoch 20/20\n",
      "9s - loss: 0.0082 - acc: 0.9986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179b99b0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    nb_epoch=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s     \n",
      "Test loss 0.0760086516795\n",
      "Test accuracy 0.9785\n"
     ]
    }
   ],
   "source": [
    "score3 = model3.evaluate(testvectors, Y_test)\n",
    "print(\"Test loss\", score3[0])\n",
    "print(\"Test accuracy\", score3[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Ahora la *accuracy* ha aumentado notablemente. La probabilidad de acertar un código postal de 9 dígitos pasa a ser $0,9785^9 = 0,8223.$</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Define a new network with two hidden layers, each of 512 hidden units with rectified linear activation. For the output use the softmax activation. Compile the defined network, choosing \"adam\" as the optimization algorithm, and train it with the data. Then measure the accuracy over the test data. How are you doing now?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(512, input_shape=(784,)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dense(512))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dense(10))\n",
    "model4.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_8 (Dense)                  (None, 512)           401920      dense_input_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 512)           0           dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 512)           262656      activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 512)           0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 10)            5130        activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 10)            0           dense_10[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "71s - loss: 0.2164 - acc: 0.9354\n",
      "Epoch 2/20\n",
      "70s - loss: 0.0793 - acc: 0.9755\n",
      "Epoch 3/20\n",
      "70s - loss: 0.0508 - acc: 0.9834\n",
      "Epoch 4/20\n",
      "73s - loss: 0.0360 - acc: 0.9884\n",
      "Epoch 5/20\n",
      "71s - loss: 0.0274 - acc: 0.9911\n",
      "Epoch 6/20\n",
      "71s - loss: 0.0215 - acc: 0.9927\n",
      "Epoch 7/20\n",
      "73s - loss: 0.0180 - acc: 0.9941\n",
      "Epoch 8/20\n",
      "71s - loss: 0.0182 - acc: 0.9940\n",
      "Epoch 9/20\n",
      "71s - loss: 0.0171 - acc: 0.9941\n",
      "Epoch 10/20\n",
      "75s - loss: 0.0127 - acc: 0.9960\n",
      "Epoch 11/20\n",
      "71s - loss: 0.0126 - acc: 0.9959\n",
      "Epoch 12/20\n",
      "71s - loss: 0.0121 - acc: 0.9962\n",
      "Epoch 13/20\n",
      "73s - loss: 0.0100 - acc: 0.9968\n",
      "Epoch 14/20\n",
      "72s - loss: 0.0081 - acc: 0.9975\n",
      "Epoch 15/20\n",
      "72s - loss: 0.0100 - acc: 0.9968\n",
      "Epoch 16/20\n",
      "73s - loss: 0.0103 - acc: 0.9970\n",
      "Epoch 17/20\n",
      "72s - loss: 0.0098 - acc: 0.9968\n",
      "Epoch 18/20\n",
      "72s - loss: 0.0095 - acc: 0.9969\n",
      "Epoch 19/20\n",
      "72s - loss: 0.0105 - acc: 0.9969\n",
      "Epoch 20/20\n",
      "73s - loss: 0.0051 - acc: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d80e48>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    nb_epoch=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s    \n",
      "\n",
      "Test loss 0.0958513206586\n",
      "Test accuracy 0.9826\n"
     ]
    }
   ],
   "source": [
    "score4 = model4.evaluate(testvectors, Y_test)\n",
    "print(\"\")\n",
    "print(\"Test loss\", score4[0])\n",
    "print(\"Test accuracy\", score4[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">El añadir una capa escondida adicional y más unidades por capa ha incrementado la *accuracy*, aunque el aumento ya no es tan notorio. Lograr una pequeña mejora implica un aumento notable de la red y, por tanto, de pasos de procesamiento. La probabilidad ahora de acertar un código postal de 9 dígitos es $0,9826^9 = 0,8539.$</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization can help improve the performance of a network, specially when the number of network parameters becomes large and this leads to better performance in training data than in test data, which is to say, overfitting. One of the most simple and effective ways of doing so is by using **dropout**. In Keras dropout is imposed on a layer by adding a **Dropout** layer just after the activation layer in which we wish to impose regularization. For instance, to create a dropout layer of a 30% probability of dropping an input unit we write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dropout at 0x17acf908>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers.core import Dropout\n",
    "Dropout(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would just need to add this layer to the model to produce the dropout effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Define a new network with two hidden layers, each of 512 hidden units with rectified linear activation. Both hidden layers should have a Dropout of 40%. For the output use the softmax activation. Compile the defined network, choosing \"adam\" as the optimization algorithm, and train it with the data. Then measure the accuracy over the test data. Has dropout helped?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "model5 = Sequential()\n",
    "model5.add(Dense(512, input_shape=(784,)))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(Dropout(0.4))\n",
    "model5.add(Dense(512))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(Dropout(0.4))\n",
    "model5.add(Dense(10))\n",
    "model5.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_11 (Dense)                 (None, 512)           401920      dense_input_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 512)           0           dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 512)           0           activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 512)           262656      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 512)           0           dense_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 512)           0           activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 10)            5130        dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 10)            0           dense_13[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "78s - loss: 0.3025 - acc: 0.9076\n",
      "Epoch 2/20\n",
      "77s - loss: 0.1338 - acc: 0.9587\n",
      "Epoch 3/20\n",
      "77s - loss: 0.0990 - acc: 0.9690\n",
      "Epoch 4/20\n",
      "78s - loss: 0.0851 - acc: 0.9735\n",
      "Epoch 5/20\n",
      "78s - loss: 0.0747 - acc: 0.9764\n",
      "Epoch 6/20\n",
      "79s - loss: 0.0644 - acc: 0.9793\n",
      "Epoch 7/20\n",
      "77s - loss: 0.0593 - acc: 0.9810\n",
      "Epoch 8/20\n",
      "76s - loss: 0.0531 - acc: 0.9828\n",
      "Epoch 9/20\n",
      "76s - loss: 0.0497 - acc: 0.9841\n",
      "Epoch 10/20\n",
      "76s - loss: 0.0438 - acc: 0.9858\n",
      "Epoch 11/20\n",
      "78s - loss: 0.0457 - acc: 0.9852\n",
      "Epoch 12/20\n",
      "77s - loss: 0.0404 - acc: 0.9866\n",
      "Epoch 13/20\n",
      "77s - loss: 0.0401 - acc: 0.9872\n",
      "Epoch 14/20\n",
      "80s - loss: 0.0384 - acc: 0.9869\n",
      "Epoch 15/20\n",
      "77s - loss: 0.0365 - acc: 0.9882\n",
      "Epoch 16/20\n",
      "76s - loss: 0.0349 - acc: 0.9892\n",
      "Epoch 17/20\n",
      "76s - loss: 0.0330 - acc: 0.9890\n",
      "Epoch 18/20\n",
      "81s - loss: 0.0337 - acc: 0.9894\n",
      "Epoch 19/20\n",
      "78s - loss: 0.0299 - acc: 0.9898\n",
      "Epoch 20/20\n",
      "78s - loss: 0.0306 - acc: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18a8aef0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    nb_epoch=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 9s     \n",
      "\n",
      "Test loss 0.06070379647\n",
      "Test accuracy 0.9846\n"
     ]
    }
   ],
   "source": [
    "score5=model5.evaluate(testvectors, Y_test)\n",
    "print(\"\")\n",
    "print(\"Test loss\", score5[0])\n",
    "print(\"Test accuracy\", score5[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Al considerar regularización mediante *dropout* ha mejorado muy ligeramente la *accuracy*, en solo dos décimas porcentuales. La probabilidad ahora de acertar un código postal de 9 dígitos es $0,9846^9 = 0,8696.$</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Try training a network with more hidden layers. Does the performance improve in any way by doing this?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_2 (Dense)                  (None, 10)            7850        dense_input_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 10)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            110         activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 10)            0           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 7,960\n",
      "Trainable params: 7,960\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "model6 = Sequential()\n",
    "model6.add(Dense(512, input_shape=(784,)))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(Dropout(0.4))\n",
    "model6.add(Dense(512))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(Dropout(0.4))\n",
    "model6.add(Dense(512))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(Dropout(0.4))\n",
    "model6.add(Dense(10))\n",
    "model6.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model6.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "114s - loss: 0.3390 - acc: 0.8947\n",
      "Epoch 2/20\n",
      "111s - loss: 0.1508 - acc: 0.9543\n",
      "Epoch 3/20\n",
      "112s - loss: 0.1194 - acc: 0.9650\n",
      "Epoch 4/20\n",
      "112s - loss: 0.0996 - acc: 0.9701\n",
      "Epoch 5/20\n",
      "114s - loss: 0.0913 - acc: 0.9732\n",
      "Epoch 6/20\n",
      "112s - loss: 0.0810 - acc: 0.9751\n",
      "Epoch 7/20\n",
      "112s - loss: 0.0716 - acc: 0.9784\n",
      "Epoch 8/20\n",
      "113s - loss: 0.0691 - acc: 0.9791\n",
      "Epoch 9/20\n",
      "114s - loss: 0.0638 - acc: 0.9805\n",
      "Epoch 10/20\n",
      "113s - loss: 0.0593 - acc: 0.9818\n",
      "Epoch 11/20\n",
      "116s - loss: 0.0584 - acc: 0.9828\n",
      "Epoch 12/20\n",
      "113s - loss: 0.0575 - acc: 0.9817\n",
      "Epoch 13/20\n",
      "112s - loss: 0.0490 - acc: 0.9846\n",
      "Epoch 14/20\n",
      "113s - loss: 0.0500 - acc: 0.9847\n",
      "Epoch 15/20\n",
      "114s - loss: 0.0476 - acc: 0.9857\n",
      "Epoch 16/20\n",
      "113s - loss: 0.0481 - acc: 0.9852\n",
      "Epoch 17/20\n",
      "113s - loss: 0.0435 - acc: 0.9872\n",
      "Epoch 18/20\n",
      "112s - loss: 0.0435 - acc: 0.9871\n",
      "Epoch 19/20\n",
      "114s - loss: 0.0426 - acc: 0.9870\n",
      "Epoch 20/20\n",
      "113s - loss: 0.0415 - acc: 0.9869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19f5a588>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    nb_epoch=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 13s    \n",
      "\n",
      "Test loss 0.0620377490216\n",
      "Test accuracy 0.9839\n"
     ]
    }
   ],
   "source": [
    "score6=model6.evaluate(testvectors,Y_test)\n",
    "print(\"\")\n",
    "print(\"Test loss\", score6[0])\n",
    "print(\"Test accuracy\", score6[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Añadir capas adicionales ya no mejora la *accuracy*. De hecho, ha habido un ligero empeoramiento.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further improve on this image recognition problem we need network layers that do consider the data as images, and take into account closeness of pixels to make decisions instead of just throwing all pixel data into a fully connected network and expect intelligence to emerge from chaos. **Convolutional** and **Pooling** layers are the best way to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the data as tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While for the perceptrons above we vectorized the data to fit into the perceptron framework, for convolutional networks we will need to shape the data in the form of a **4-dimensional tensor**. The dimensions of such tensor represent the following:\n",
    "* Image index (e.g. 3th image in the dataset)\n",
    "* Row index\n",
    "* Column index\n",
    "* Channel index (e.g. colour channel in colored images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again make use of the reshape function to perform this transformation. We have 60000 images in our training set, and those images have 28 rows x 28 columns. Since these images are grayscale, the channel dimension only contains one channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traintensor = X_train.reshape(60000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Repeat the transformation for the test data. Save the resulting tensor in a variable named *testtensor*.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "testtensor = X_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When defining a convolutional network, Convolution and Pooling layers work together. The most popular way of using these layers is in the following pattern:\n",
    "* A Convolution layer with rectified linear activations\n",
    "* A Pooling layer\n",
    "* Dropout (if regularization wants to be enforced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can thus define a minimal convolutional network as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "kernel_size = 3 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "model7 = Sequential()\n",
    "\n",
    "model7.add(Convolution2D(32, # Number convolution channels to generate\n",
    "                        kernel_size, kernel_size, # Size of convolution kernels\n",
    "                        border_mode='valid', # Strategy to deal with borders\n",
    "                        input_shape=(img_rows, img_cols, 1))) # Size = image rows x image columns x channels\n",
    "model7.add(Activation('relu'))\n",
    "model7.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "model7.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an issue, though: at some point we need to transform the tensor data into a vector, as the output of the network should be a vector of 10 values, representing class probabilities. We can do this by using a **Flatten** layer. Then we can add a standard Dense layer to produce the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Flatten\n",
    "model7.add(Flatten())\n",
    "model7.add(Dense(10))\n",
    "model7.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Compile the defined network, choosing \"adam\" as the optimization algorithm, and train it with the data. Use the tensor data you prepared above, not the vectorized data. Then measure the accuracy over the test data. Have the Convolution and MaxPooling helped?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "model7.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "305s - loss: 0.3575 - acc: 0.9017\n",
      "Epoch 2/20\n",
      "350s - loss: 0.1449 - acc: 0.9589\n",
      "Epoch 3/20\n",
      "309s - loss: 0.1047 - acc: 0.9700\n",
      "Epoch 4/20\n",
      "321s - loss: 0.0854 - acc: 0.9753\n",
      "Epoch 5/20\n",
      "317s - loss: 0.0765 - acc: 0.9770\n",
      "Epoch 6/20\n",
      "302s - loss: 0.0697 - acc: 0.9790\n",
      "Epoch 7/20\n",
      "327s - loss: 0.0634 - acc: 0.9806\n",
      "Epoch 8/20\n",
      "297s - loss: 0.0588 - acc: 0.9818\n",
      "Epoch 9/20\n",
      "195s - loss: 0.0553 - acc: 0.9827\n",
      "Epoch 10/20\n",
      "196s - loss: 0.0501 - acc: 0.9850\n",
      "Epoch 11/20\n",
      "199s - loss: 0.0484 - acc: 0.9850\n",
      "Epoch 12/20\n",
      "193s - loss: 0.0470 - acc: 0.9856\n",
      "Epoch 13/20\n",
      "194s - loss: 0.0425 - acc: 0.9868\n",
      "Epoch 14/20\n",
      "194s - loss: 0.0417 - acc: 0.9867\n",
      "Epoch 15/20\n",
      "197s - loss: 0.0406 - acc: 0.9873\n",
      "Epoch 16/20\n",
      "195s - loss: 0.0372 - acc: 0.9887\n",
      "Epoch 17/20\n",
      "196s - loss: 0.0362 - acc: 0.9885\n",
      "Epoch 18/20\n",
      "195s - loss: 0.0344 - acc: 0.9893\n",
      "Epoch 19/20\n",
      "192s - loss: 0.0327 - acc: 0.9890\n",
      "Epoch 20/20\n",
      "195s - loss: 0.0313 - acc: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b12c9e8>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.fit(\n",
    "    traintensor, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    nb_epoch=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 27s    \n",
      "\n",
      "Test loss 0.0480747123877\n",
      "Test accuracy 0.9848\n"
     ]
    }
   ],
   "source": [
    "score7 = model7.evaluate(testtensor, Y_test)\n",
    "print(\"\")\n",
    "print(\"Test loss\", score7[0])\n",
    "print(\"Test accuracy\", score7[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Apenas ha habido mejora respecto al modelo 5 de dos capas ocultas con dropout. La *accuracy* ha pasado de 0,9846 a 0,9848.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Build and train a convolutional network with the following layers:\n",
    "<ul>\n",
    "     <li>A Convolution layer of 32 channels, kernel size 3 and rectified linear activation</li>\n",
    "     <li>Another Convolution layer of 32 channels, kernel size 3 and rectified linear activation</li>\n",
    "     <li>A MaxPooling layer of size 2</li>\n",
    "     <li>A 25% Dropout</li>\n",
    "     <li>A Flatten layer</li>\n",
    "     <li>A Dense layer with 128 units and rectified linear activation</li>\n",
    "     <li>A 50% Dropout</li>\n",
    "     <li>An output Dense layer with softmax activation</li>\n",
    "</ul>\n",
    "Has the added complexity improved the accuracy results?    \n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_3 (Convolution2D)  (None, 26, 26, 32)    320         convolution2d_input_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 26, 26, 32)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 24, 24, 32)    9248        activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 24, 24, 32)    0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 12, 12, 32)    0           activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 12, 12, 32)    0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 4608)          0           dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_19 (Dense)                 (None, 128)           589952      flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 128)           0           dense_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 128)           0           activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_20 (Dense)                 (None, 10)            1290        dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 10)            0           dense_20[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 600,810\n",
      "Trainable params: 600,810\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "model8 = Sequential()\n",
    "model8.add(Convolution2D(32,\n",
    "                       kernel_size, kernel_size,\n",
    "                       border_mode='valid',\n",
    "                       input_shape=(img_rows,img_cols,1)))\n",
    "model8.add(Activation('relu'))\n",
    "model8.add(Convolution2D(32,\n",
    "                       kernel_size, kernel_size,\n",
    "                       border_mode='valid',\n",
    "                       input_shape=(img_rows,img_cols,1)))\n",
    "model8.add(Activation('relu'))\n",
    "model8.add((MaxPooling2D(pool_size=(pool_size,pool_size))))\n",
    "model8.add(Dropout(0.25))\n",
    "model8.add(Flatten())\n",
    "model8.add(Dense(128))\n",
    "model8.add(Activation('relu'))\n",
    "model8.add(Dropout(0.5))\n",
    "model8.add(Dense(10))\n",
    "model8.add(Activation('softmax'))\n",
    "\n",
    "model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model8.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "824s - loss: 0.2811 - acc: 0.9151\n",
      "Epoch 2/20\n",
      "812s - loss: 0.0981 - acc: 0.9705\n",
      "Epoch 3/20\n",
      "814s - loss: 0.0723 - acc: 0.9786\n",
      "Epoch 4/20\n",
      "830s - loss: 0.0585 - acc: 0.9811\n",
      "Epoch 5/20\n",
      "819s - loss: 0.0517 - acc: 0.9844\n",
      "Epoch 6/20\n",
      "853s - loss: 0.0453 - acc: 0.9857\n",
      "Epoch 7/20\n",
      "862s - loss: 0.0415 - acc: 0.9868\n",
      "Epoch 8/20\n",
      "829s - loss: 0.0380 - acc: 0.9885\n",
      "Epoch 9/20\n",
      "820s - loss: 0.0349 - acc: 0.9885\n",
      "Epoch 10/20\n",
      "814s - loss: 0.0324 - acc: 0.9899\n",
      "Epoch 11/20\n",
      "883s - loss: 0.0299 - acc: 0.9904\n",
      "Epoch 12/20\n",
      "821s - loss: 0.0297 - acc: 0.9906\n",
      "Epoch 13/20\n",
      "824s - loss: 0.0261 - acc: 0.9916\n",
      "Epoch 14/20\n",
      "813s - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 15/20\n",
      "830s - loss: 0.0221 - acc: 0.9928\n",
      "Epoch 16/20\n",
      "840s - loss: 0.0220 - acc: 0.9926\n",
      "Epoch 17/20\n",
      "830s - loss: 0.0222 - acc: 0.9929\n",
      "Epoch 18/20\n",
      "813s - loss: 0.0205 - acc: 0.9929\n",
      "Epoch 19/20\n",
      "839s - loss: 0.0203 - acc: 0.9934\n",
      "Epoch 20/20\n",
      "842s - loss: 0.0192 - acc: 0.9935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b67cfd0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8.fit(traintensor, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    nb_epoch=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 65s    \n",
      "\n",
      "Test loss 0.0287200998663\n",
      "Test accuracy 0.9922\n"
     ]
    }
   ],
   "source": [
    "score8 = model8.evaluate(testtensor, Y_test)\n",
    "print(\"\")\n",
    "print(\"Test loss\", score8[0])\n",
    "print(\"Test accuracy\", score8[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Las dos capas de convolución han conseguido mejorar la *accuracy*, que ha pasado de 0,9848 a 0,9922.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final exercise: LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=http://yann.lecun.com/exdb/lenet/>LeNet</a> is a particular convolutional neural network definition that has proven to be quite effective. As a final excercise we will build this network and try it on our digits problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/question.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Build and train a LeNet network, which is defined by the following layers:\n",
    "<ul>\n",
    "     <li>A Convolution layer of 20 channels, kernel size 5 and rectified linear activation</li>\n",
    "     <li>A MaxPooling layer of size 2 and stride 2 (check <a href=http://keras.io/layers/convolutional/>the docs</a>)</li>\n",
    "     <li>A 25% Dropout</li>\n",
    "     <li>A Convolution layer of 50 channels, kernel size 5 and rectified linear activation</li>\n",
    "     <li>A MaxPooling layer of size 2 and stride 2 (check <a href=http://keras.io/layers/convolutional/>the docs</a>)</li>\n",
    "     <li>A 25% Dropout</li>\n",
    "     <li>A Flatten layer</li>\n",
    "     <li>A Dense layer with 500 units and rectified linear activation</li>\n",
    "     <li>A 50% Dropout</li>\n",
    "     <li>An output Dense layer with softmax activation</li>\n",
    "</ul>\n",
    "Is this the best network so far for the problem?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_5 (Convolution2D)  (None, 24, 24, 20)    520         convolution2d_input_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 24, 24, 20)    0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 12, 12, 20)    0           activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 12, 12, 20)    0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 8, 8, 50)      25050       dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 8, 8, 50)      0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 4, 4, 50)      0           activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 4, 4, 50)      0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 800)           0           dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_21 (Dense)                 (None, 500)           400500      flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 500)           0           dense_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 500)           0           activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_22 (Dense)                 (None, 10)            5010        dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 10)            0           dense_22[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 431,080\n",
      "Trainable params: 431,080\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "kernel_size = 5\n",
    "pool_size = 2\n",
    "strides = 2\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "\n",
    "model_LeNet = Sequential()\n",
    "model_LeNet.add (Convolution2D(20,\n",
    "                      kernel_size, kernel_size,\n",
    "                      border_mode='valid',\n",
    "                      input_shape=(img_rows,img_cols,1)))\n",
    "model_LeNet.add(Activation('relu'))\n",
    "model_LeNet.add(MaxPooling2D(pool_size=(pool_size,pool_size),strides=(strides,strides)))\n",
    "model_LeNet.add(Dropout(0.25))\n",
    "model_LeNet.add(Convolution2D(50,\n",
    "                     kernel_size,kernel_size,\n",
    "                     border_mode='valid',\n",
    "                     input_shape=(img_rows,img_cols,1)))\n",
    "model_LeNet.add(Activation('relu'))\n",
    "model_LeNet.add(MaxPooling2D(pool_size=(pool_size,pool_size),strides=(strides,strides)))\n",
    "model_LeNet.add(Dropout(0.25))\n",
    "model_LeNet.add(Flatten())\n",
    "model_LeNet.add(Dense(500))\n",
    "model_LeNet.add(Activation('relu'))\n",
    "model_LeNet.add(Dropout(0.5))\n",
    "model_LeNet.add(Dense(10))\n",
    "model_LeNet.add(Activation('softmax'))\n",
    "\n",
    "model_LeNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_LeNet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "416s - loss: 0.2553 - acc: 0.9209\n",
      "Epoch 2/20\n",
      "405s - loss: 0.0779 - acc: 0.9761\n",
      "Epoch 3/20\n",
      "360s - loss: 0.0576 - acc: 0.9820\n",
      "Epoch 4/20\n",
      "366s - loss: 0.0491 - acc: 0.9844\n",
      "Epoch 5/20\n",
      "361s - loss: 0.0433 - acc: 0.9866\n",
      "Epoch 6/20\n",
      "365s - loss: 0.0384 - acc: 0.9879\n",
      "Epoch 7/20\n",
      "360s - loss: 0.0352 - acc: 0.9890\n",
      "Epoch 8/20\n",
      "360s - loss: 0.0314 - acc: 0.9901\n",
      "Epoch 9/20\n",
      "359s - loss: 0.0295 - acc: 0.9906\n",
      "Epoch 10/20\n",
      "363s - loss: 0.0278 - acc: 0.9910\n",
      "Epoch 11/20\n",
      "361s - loss: 0.0253 - acc: 0.9922\n",
      "Epoch 12/20\n",
      "357s - loss: 0.0247 - acc: 0.9921\n",
      "Epoch 13/20\n",
      "360s - loss: 0.0246 - acc: 0.9921\n",
      "Epoch 14/20\n",
      "363s - loss: 0.0213 - acc: 0.9928\n",
      "Epoch 15/20\n",
      "360s - loss: 0.0198 - acc: 0.9935\n",
      "Epoch 16/20\n",
      "357s - loss: 0.0208 - acc: 0.9935\n",
      "Epoch 17/20\n",
      "358s - loss: 0.0191 - acc: 0.9939\n",
      "Epoch 18/20\n",
      "358s - loss: 0.0181 - acc: 0.9942\n",
      "Epoch 19/20\n",
      "367s - loss: 0.0171 - acc: 0.9943\n",
      "Epoch 20/20\n",
      "368s - loss: 0.0182 - acc: 0.9941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c65be80>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LeNet.fit(\n",
    "    traintensor, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    nb_epoch=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 40s    \n",
      "\n",
      "Test loss 0.0195378797124\n",
      "Test accuracy 0.9946\n"
     ]
    }
   ],
   "source": [
    "score_LeNet = model_LeNet.evaluate(testtensor, Y_test)\n",
    "print(\"\")\n",
    "print(\"Test loss\", score_LeNet[0])\n",
    "print(\"Test accuracy\", score_LeNet[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">La red LeNet es el mejor modelo hasta el momento. Ha conseguido elevar la *accuracy* hasta 0,9946. Solo falla en 54 imágenes de las 10 000 del conjunto de test. Ahora la probabilidad de acertar correctamente un código postal de 9 dígitos es $0,9946^9 = 0,9524. Una probabilidad bastante buena ya.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.<br>\n",
    "                          THIS IS THE END OF THE ASSIGNMENT<br>\n",
    "~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.<br>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/pro.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "Rebuild the LeNet network with a larger number of training epochs. What is the best test error you can achieve?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "364s - loss: 0.0171 - acc: 0.9942\n",
      "Epoch 2/40\n",
      "363s - loss: 0.0158 - acc: 0.9950\n",
      "Epoch 3/40\n",
      "361s - loss: 0.0155 - acc: 0.9950\n",
      "Epoch 4/40\n",
      "361s - loss: 0.0159 - acc: 0.9947\n",
      "Epoch 5/40\n",
      "358s - loss: 0.0140 - acc: 0.9956\n",
      "Epoch 6/40\n",
      "358s - loss: 0.0152 - acc: 0.9950\n",
      "Epoch 7/40\n",
      "358s - loss: 0.0140 - acc: 0.9950\n",
      "Epoch 8/40\n",
      "360s - loss: 0.0138 - acc: 0.9954\n",
      "Epoch 9/40\n",
      "358s - loss: 0.0138 - acc: 0.9953\n",
      "Epoch 10/40\n",
      "366s - loss: 0.0136 - acc: 0.9954\n",
      "Epoch 11/40\n",
      "364s - loss: 0.0141 - acc: 0.9955\n",
      "Epoch 12/40\n",
      "360s - loss: 0.0133 - acc: 0.9955\n",
      "Epoch 13/40\n",
      "361s - loss: 0.0133 - acc: 0.9956\n",
      "Epoch 14/40\n",
      "359s - loss: 0.0130 - acc: 0.9959\n",
      "Epoch 15/40\n",
      "362s - loss: 0.0137 - acc: 0.9952\n",
      "Epoch 16/40\n",
      "359s - loss: 0.0116 - acc: 0.9964\n",
      "Epoch 17/40\n",
      "361s - loss: 0.0102 - acc: 0.9966\n",
      "Epoch 18/40\n",
      "366s - loss: 0.0117 - acc: 0.9963\n",
      "Epoch 19/40\n",
      "364s - loss: 0.0111 - acc: 0.9963\n",
      "Epoch 20/40\n",
      "361s - loss: 0.0117 - acc: 0.9962\n",
      "Epoch 21/40\n",
      "365s - loss: 0.0106 - acc: 0.9963\n",
      "Epoch 22/40\n",
      "360s - loss: 0.0107 - acc: 0.9969\n",
      "Epoch 23/40\n",
      "367s - loss: 0.0112 - acc: 0.9964\n",
      "Epoch 24/40\n",
      "358s - loss: 0.0100 - acc: 0.9967\n",
      "Epoch 25/40\n",
      "391s - loss: 0.0117 - acc: 0.9964\n",
      "Epoch 26/40\n",
      "382s - loss: 0.0111 - acc: 0.9964\n",
      "Epoch 27/40\n",
      "373s - loss: 0.0113 - acc: 0.9964\n",
      "Epoch 28/40\n",
      "375s - loss: 0.0111 - acc: 0.9965\n",
      "Epoch 29/40\n",
      "394s - loss: 0.0099 - acc: 0.9969\n",
      "Epoch 30/40\n",
      "359s - loss: 0.0112 - acc: 0.9965\n",
      "Epoch 31/40\n",
      "364s - loss: 0.0101 - acc: 0.9968\n",
      "Epoch 32/40\n",
      "363s - loss: 0.0114 - acc: 0.9963\n",
      "Epoch 33/40\n",
      "385s - loss: 0.0102 - acc: 0.9965\n",
      "Epoch 34/40\n",
      "381s - loss: 0.0105 - acc: 0.9966\n",
      "Epoch 35/40\n",
      "373s - loss: 0.0121 - acc: 0.9968\n",
      "Epoch 36/40\n",
      "354s - loss: 0.0088 - acc: 0.9972\n",
      "Epoch 37/40\n",
      "382s - loss: 0.0101 - acc: 0.9968\n",
      "Epoch 38/40\n",
      "379s - loss: 0.0101 - acc: 0.9970\n",
      "Epoch 39/40\n",
      "402s - loss: 0.0092 - acc: 0.9969\n",
      "Epoch 40/40\n",
      "357s - loss: 0.0093 - acc: 0.9969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c7b9978>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LeNet.fit(\n",
    "    traintensor, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    nb_epoch=40, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 40s    \n",
      "\n",
      "Test loss 0.0335501043057\n",
      "Test accuracy 0.9934\n"
     ]
    }
   ],
   "source": [
    "score_LeNet = model_LeNet.evaluate(testtensor, Y_test)\n",
    "print(\"\")\n",
    "print(\"Test loss\", score_LeNet[0])\n",
    "print(\"Test accuracy\", score_LeNet[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Aumentar el número de *epochs* (40) no ha mejorado la *accuracy*. De hecho, ha habido un ligero empeoramiento respecto del modelo LeNet anterior (20 epochs).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td><img src=\"img/pro.png\" style=\"width:80px;height:80px;\"></td><td>\n",
    "If your PC has a CUDA-compatible GPU card you can take advantage of it to significanly accelerate training times. You are encouraged to configure Keras to make use of your GPU.\n",
    " </td></tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
