{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de sentimientos con reviews de productos de Amazon España (opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si has hecho ya el ejercicio de web scraping con `Requests` y `BeautifulSoup` habrás visto cómo extraer datos de una página web.\n",
    "\n",
    "El dataset que utilizarás en este ejercicio (que no es obligatorio entregar) lo he generado utilizando `Scrapy` y `BeautifulSoup`, y contiene unas $700.000$ entradas con dos columnas: el número de estrellas dadas por un usuario a un determinado producto y el comentario sobre dicho producto; exactamente igual que en el ejercico de scraping.\n",
    "\n",
    "Ahora, tu objetivo es utilizar técnicas de procesamiento de lenguaje natural para hacer un clasificador que sea capaz de distinguir (¡y predecir!) si un comentario es positivo o negativo.\n",
    "\n",
    "Es un ejercicio MUY complicado, más que nada porque versa sobre técnicas que no hemos visto en clase. Así que si quieres resolverlo, te va a tocar estudiar y *buscar por tu cuenta*; exactamente igual que como sería en un puesto de trabajo. Dicho esto, daré un par de pistas:\n",
    "\n",
    "+ El número de estrellas que un usuario da a un producto es el indicador de si a dicho usuario le ha gustado el producto o no. Una persona que da 5 estrellas (el máximo) a un producto probablemente esté contento con él, y el comentario será por tanto positivo; mientras que cuando una persona da 1 estrella a un producto es porque no está satisfecha... \n",
    "+ Teniendo el número de estrellas podríamos resolver el problema como si fuera de regresión; pero vamos a establecer una regla para convertirlo en problema de clasificación: *si una review tiene 4 o más estrellas, se trata de una review positiva; y será negativa si tiene menos de 4 estrellas*. Así que probablemente te toque transformar el número de estrellas en otra variable que sea *comentario positivo/negativo*.\n",
    "\n",
    "Y... poco más. Lo más complicado será convertir el texto de cada review en algo que un clasificador pueda utilizar y entender (puesto que los modelos no entienden de palabras, sino de números). Aquí es donde te toca investigar las técnicas para hacerlo. El ejercicio se puede conseguir hacer, y obtener buenos resultados, utilizando únicamente Numpy, pandas y Scikit-Learn; pero siéntete libre de utilizar las bibliotecas que quieras.\n",
    "\n",
    "Ahora escribiré una serie de *keywords* que probablemente te ayuden a saber qué buscar:\n",
    "\n",
    "`bag of words, tokenizer, tf, idf, tf-idf, sklearn.feature_extraction, scipy.sparse, NLTK (opcional), stemmer, lemmatizer, stop-words removal, bigrams, trigrams`\n",
    "\n",
    "No te desesperes si te encuentras muy perdido/a y no consigues sacar nada. Tras la fecha de entrega os daré un ejemplo de solución explicado con todo el detalle posible.\n",
    "\n",
    "¡Ánimo y buena suerte!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLUCIÓN 1\n",
    "Se trata de un ejemplo de aprendizaje automático supervisado (clasificación) en el que las *features* son las palabras de cada comentario (*tokens*) y la *target* es el número de estrellas, que hay que convertir en variable binaria (positivo o negativo).  \n",
    "Para resolverlo voy a utilizar herramientas de las librerías **nltk** y **sklearn.feature_extraction**. Lo más difícil es transformar el texto de los comentarios en un formato que pueda entender el clasificador Naïve Bayes que voy a usar.  \n",
    "El primer paso es leer los datos. Como el fichero proporcionado viene en formato csv, voy a cargarlo con la función read_csv de pandas. Esto lo convertirá en un DataFrame que transformaré en array de numpy para manipularlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entrada=pd.read_csv(\"amazon_es_reviews.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veo qué pinta tienen los datos y compruebo que son de tipo DataFrame.  \n",
    "Los comentarios contienen faltas de ortografía, palabras mal escritas, signos de puntuación y mayúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comentario</th>\n",
       "      <th>estrellas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Para chicas es perfecto, ya que la esfera no e...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muy floja la cuerda y el anclaje es de mala ca...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Razonablemente bien escrito, bien ambientado, ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hola! No suel o escribir muchas opiniones sobr...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A simple vista m parecia una buena camara pero...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          comentario  estrellas\n",
       "0  Para chicas es perfecto, ya que la esfera no e...        4.0\n",
       "1  Muy floja la cuerda y el anclaje es de mala ca...        1.0\n",
       "2  Razonablemente bien escrito, bien ambientado, ...        3.0\n",
       "3  Hola! No suel o escribir muchas opiniones sobr...        5.0\n",
       "4  A simple vista m parecia una buena camara pero...        1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrada.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(entrada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación separo los comentarios y el número de estrellas en sendos arrays de numpy para manipularlos independientemente. Más adelante la información aportada por cada uno se volverá a reunir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comentarios=np.array(entrada[\"comentario\"])\n",
    "puntuaciones=np.array(entrada[\"estrellas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702446\n",
      "702446\n"
     ]
    }
   ],
   "source": [
    "print(len(comentarios))\n",
    "print(len(puntuaciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(comentarios))\n",
    "print(type(puntuaciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se trata de un problema de clasificación; así que voy a convertir la *target*, el número de estrellas (entre 1 y 5), en una variable nominal con dos valores (neg y pos) de manera que los valores de 4 y 5 estrellas los asigno al valor positivo y el resto de valores numéricos al valor negativo. Para ello defino una función de conversión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertidor(numeros):\n",
    "    listado=[]\n",
    "    for numero in numeros:\n",
    "        if numero>3:\n",
    "            listado.append('pos')\n",
    "            \n",
    "        else:\n",
    "            listado.append('neg')\n",
    "            \n",
    "    return listado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hago unas pruebas con unos pocos números para comprobar que la función que he definido acepta y devuelve listas y funciona correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'neg', 'neg', 'pos', 'pos', 'neg', 'neg']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puntu=convertidor([1,2,0,4,5,3,0])\n",
    "puntu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.,  1.,  3.,  5.,  1.,  1.,  2.,  3.,  3.,  5.])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puntuaciones[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos', 'neg', 'neg', 'pos', 'neg', 'neg', 'neg', 'neg', 'neg', 'pos']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punt2=convertidor(puntuaciones[:10])\n",
    "punt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que funciona; así que le paso ya como argumento todo el array de puntuaciones y compruebo su longitud y algunos de sus elementos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punt=convertidor(puntuaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702446"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(punt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos', 'neg', 'neg', 'pos', 'neg', 'neg', 'neg', 'neg', 'neg', 'pos']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punt[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es correcto.  \n",
    "Ya he transformado la columna del número de estrellas, ahora tengo que transformar la otra, la de los comentarios. Empiezo echándole un vistazo al array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'Para chicas es perfecto, ya que la esfera no es muy grande y la correa se adapta a las muñecas más finas. Un pelín gordo (para mi gusto). La carga por movimiento no dura mucho. Después de 1-2 días sin llevarlo se para.'\n",
      " 'Muy floja la cuerda y el anclaje es de mala calidad. El metal  Se dobla muy fácilmente. No lo recomiendo'\n",
      " 'Razonablemente bien escrito, bien ambientado, quizás previsible, pero historia interesante. Los personajes están muy bien dibujados. Me parece un libro recomendable.']\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(comentarios[:3])\n",
    "\n",
    "print(type(comentarios))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso (de los más importantes) es *tokenizar* todo el corpus de documentos de texto (cada comentario viene a ser un documento) para que el clasificador que se empleará posteriormente lo pueda entender.  \n",
    "Los *tokens* son unidades de información en las que se descompone un texto (o imagen) a analizar, por ejemplo, palabras o letras, signos de puntuación, etc. En este caso voy a emplear un *tokenizer* para descomponer en palabras. Hay palabras que se repiten mucho en todos los textos y que no aportan ninguna información, como preposiciones, conjunciones, pronombres, etc. A estas palabras se las conoce como *stop words* y hay que eliminarlas del listado de *tokens*. Como estoy analizando textos en español, necesito una lista de *stop words* en español. Voy a importarla de la librería **nltk** (Natural Lenguage Tool Kit).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spanish_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spanish_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'la',\n",
       " 'que',\n",
       " 'el',\n",
       " 'en',\n",
       " 'y',\n",
       " 'a',\n",
       " 'los',\n",
       " 'del',\n",
       " 'se',\n",
       " 'las',\n",
       " 'por',\n",
       " 'un',\n",
       " 'para',\n",
       " 'con']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_stopwords[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tengo la lista de *stop words* en español. Ahora, para *tokenizar* voy a usar la clase CountVectorizer de la librería **sklearn.feature_extraction**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hago una instancia de dicha clase pasándole la lista de *stop words* en español como atributo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer_esp = CountVectorizer(min_df=1,stop_words=spanish_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la instancia que acabo de crear le aplico el método build_analyzer() y le paso una cadena de texto sencillo y un elemento de la lista de comentarios para comprobar que acepta/devuelve listas como entrada/salida y que *tokeniza* correctamente convirtiendo las palabras en minúsculas y eliminando signos de puntuación y las *stop words* incluidas en el listado anterior (este, un, de, es, para...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analizador = vectorizer_esp.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['documento', 'texto', 'analizar', 'fácilmente']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analizador(\"Este es un Documento de texTo para aNAlizar fácilmente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chicas', 'perfecto', 'esfera', 'grande', 'correa', 'adapta', 'muñecas', 'finas', 'pelín', 'gordo', 'gusto', 'carga', 'movimiento', 'dura', 'después', 'días', 'llevarlo']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "tokens= analizador(comentarios[0])\n",
    "print(tokens)\n",
    "print(type(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciona correctamente. Ahora tengo que ir convirtiendo progresivamente el formato de los *tokens* hasta darles la estructura necesaria para poder usar el clasificador. Defino una función palabra_feat para convertir cada una de las listas de tokens de cada comentario en diccionarios en los que las claves son las palabras y los valores son todos el booleano True. Hago una pequeña prueba solo con la lista de *tokens* extraída del primer comentario.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def palabra_feat(palabras):\n",
    "    return dict([(palabra, True) for palabra in palabras])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adapta': True,\n",
       " 'carga': True,\n",
       " 'chicas': True,\n",
       " 'correa': True,\n",
       " 'después': True,\n",
       " 'dura': True,\n",
       " 'días': True,\n",
       " 'esfera': True,\n",
       " 'finas': True,\n",
       " 'gordo': True,\n",
       " 'grande': True,\n",
       " 'gusto': True,\n",
       " 'llevarlo': True,\n",
       " 'movimiento': True,\n",
       " 'muñecas': True,\n",
       " 'pelín': True,\n",
       " 'perfecto': True}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba=palabra_feat(tokens)\n",
    "prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación convierto todas las listas de *tokens* de todos los comentarios en diccionarios y vuelvo a recombinar esta información con la procedente del número de estrellas (recuérdese que esta ya está convertida en variable binaria de valores pos y neg). En este paso se obtiene el formato final que consiste en dos **listas** separadas (una para comentarios positivos y otra para negativos) de **duplas** donde cada dupla contiene un **diccionario** de *tokens* como claves y el booleano True como valores y la cadena 'neg' o 'pos' según sea negativo o positivo el comentario correspondiente, es decir:  \n",
    "[ ( {'token1':True, 'token2':True,...},'neg'), ({...},'neg'),..., ({...},'neg') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'fácilmente': True, 'dobla': True, 'cuerda': True, 'anclaje': True, 'calidad': True, 'metal': True, 'recomiendo': True, 'floja': True, 'mala': True}, 'neg'), ({'previsible': True, 'personajes': True, 'recomendable': True, 'ambientado': True, 'parece': True, 'historia': True, 'escrito': True, 'bien': True, 'razonablemente': True, 'interesante': True, 'dibujados': True, 'quizás': True, 'libro': True}, 'neg'), ({'entro': True, 'decepcione': True, 'casa': True, 'simple': True, 'parecia': True, 'baño': True, 'primer': True, 'camara': True, 'yeve': True, 'decepción': True, 'agua': True, 'probe': True, 'primero': True, 'gran': True, 'buena': True, 'acuario': True, 'adios': True, 'vista': True, 'muxo': True}, 'neg')]\n",
      "\n",
      "[({'perfecto': True, 'esfera': True, 'gordo': True, 'grande': True, 'pelín': True, 'muñecas': True, 'después': True, 'llevarlo': True, 'adapta': True, 'finas': True, 'movimiento': True, 'días': True, 'carga': True, 'correa': True, 'dura': True, 'gusto': True, 'chicas': True}, 'pos'), ({'mal': True, 'barba': True, 'polvo': True, 'ver': True, 'gel': True, 'resultado': True, 'usar': True, 'sigue': True, 'funcionan': True, 'día': True, 'cuello': True, 'sensible': True, 'vamos': True, 'espuma': True, 'varias': True, 'recortador': True, 'bigote': True, 'seco': True, 'pasada': True, 'prestaciones': True, 'cara': True, 'cuchillas': True, 'viva': True, 'finalmente': True, 'productos': True, 'rojeces': True, 'escozor': True, 'escribir': True, 'láminas': True, 'producto': True, 'delicadas': True, 'absoluto': True, 'piel': True, 'buena': True, 'aun': True, 'pieles': True, 'doble': True, 'duda': True, 'años': True, 'investigar': True, 'iba': True, 'ah': True, 'hola': True, 'compré': True, 'leyendo': True, 'fácil': True, 'potente': True, 'conseguir': True, 'además': True, 'comprar': True, 'potencia': True, 'iban': True, 'apurado': True, 'segunda': True, 'usado': True, 'braún': True, 'duraba': True, 'decidí': True, 'patillas': True, 'pagar': True, 'verdad': True, 'después': True, 'volví': True, 'debajo': True, 'mach3': True, 'maravilla': True, 'carga': True, 'hora': True, 'vi': True, 'dañado': True, 'vez': True, 'obviamente': True, 'dediqué': True, 'uso': True, 'carne': True, 'si': True, 'trae': True, 'merece': True, 'apurar': True, 'parte': True, 'ergonómica': True, 'ducha': True, 'sabía': True, 'panasonic': True, 'mismo': True, 'sólo': True, 'robusta': True, 'dejaban': True, 'limpia': True, 'súper': True, 'calidad': True, 'bien': True, 'encima': True, 'excelente': True, 'experiencia': True, 'muchas': True, 'importante': True, 'máquinas': True, 'suel': True, 'desencantado': True, 'afeitadora': True, 'llevo': True, 'batería': True, 'ardor': True, 'afeitadoras': True, 'afeitar': True, 'compro': True, 'semanas': True, 'mejor': True, 'rotatorias': True, 'puedes': True, 'así': True, 'máquina': True, 'apuran': True, 'hace': True, 'ir': True, 'mala': True, 'opiniones': True, 'philips': True, 'cien': True, 'buenísimo': True, 'hice': True, 'foros': True, 'gillette': True, 'mojado': True, 'tan': True, 'afeitadas': True, 'afeita': True, 'dejé': True, 'pasé': True, 'materiales': True, 'extremadamente': True, 'recomiendo': True, 'cinco': True, 'demás': True}, 'pos'), ({'evolucionando': True, 'filósofos': True, 'simple': True, 'conceptos': True, 'corrientes': True, 'pensamientos': True, 'entretenida': True, 'sencilla': True, 'historia': True, 'paso': True, 'entender': True, 'forma': True, 'explica': True, 'permitiendo': True, 'grandes': True}, 'pos')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "negprueba=[]\n",
    "posprueba=[]\n",
    "\n",
    "for i in range(len(punt)):\n",
    "    tokens0=analizador(comentarios[i])\n",
    "    \n",
    "    if punt[i]==\"pos\":\n",
    "        posprueba.append((palabra_feat(tokens0),'pos'))\n",
    "    if punt[i]=='neg':\n",
    "        negprueba.append((palabra_feat(tokens0),'neg'))\n",
    "    tokens0=[]\n",
    "\n",
    "print(negprueba[:3])\n",
    "print(\"\")\n",
    "print(posprueba[:3])\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compruebo que la longitud de ambas listas suman los 702466 comentarios iniciales y calculo cuánto es el 75% de su extensión para dividir en conjuntos de *training* y *test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338711\n",
      "363735\n"
     ]
    }
   ],
   "source": [
    "print(len(negprueba))\n",
    "print(len(posprueba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254033.25"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negprueba)*3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272801.25"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posprueba)*3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainprueba=negprueba[:254033]+posprueba[:272801]\n",
    "testprueba=negprueba[254033:]+posprueba[272801:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 526834 instances, test on 175612 instances\n"
     ]
    }
   ],
   "source": [
    "print (\"train on %d instances, test on %d instances\" %(len(trainprueba), len(testprueba)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora importo el clasificador Naïve Bayes de la librería **nltk**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entreno el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clasificadorprueba = NaiveBayesClassifier.train(trainprueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y uso el conjunto de *test* para obtener la puntuación del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.799153816367902\n"
     ]
    }
   ],
   "source": [
    "print ('accuracy:', nltk.classify.util.accuracy(clasificadorprueba, testprueba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último imprimo las palabras más relevantes con el método show_most_informative_features():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                malisima = True              neg : pos    =    107.5 : 1.0\n",
      "                malísima = True              neg : pos    =     58.0 : 1.0\n",
      "                  fraude = True              neg : pos    =     56.0 : 1.0\n",
      "              devolvería = True              neg : pos    =     55.6 : 1.0\n",
      "                    timo = True              neg : pos    =     52.3 : 1.0\n",
      "                 revisen = True              neg : pos    =     50.5 : 1.0\n",
      "                devuelvo = True              neg : pos    =     49.9 : 1.0\n",
      "                estafada = True              neg : pos    =     49.2 : 1.0\n",
      "              desprendió = True              neg : pos    =     48.3 : 1.0\n",
      "                  pesimo = True              neg : pos    =     45.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "clasificadorprueba.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLUCIÓN 2\n",
    "A continuación voy a resolver el ejercicio de manera distinta usando un algoritmo Random Forest y el modelo *bag of words* y construyendo un *tokenizer* propio para ir viendo cómo es el proceso paso a paso (el *tokenizer* de la solución 1 lo construí de automáticamente con la clase CountVectorizer).  \n",
    "Empiezo importando la librería **re** para usar expresiones regulares y la clase BeautifulSoup de la librería **bs4**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hago un par de pruebas de limpieza de textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ejemplo=\"Esto es una Prueba 0 para reemplazar! ciertos , elementos;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casy\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file C:\\Users\\Casy\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "ejemplo1=BeautifulSoup(ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ejemplo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esto es una Prueba   para reemplazar  ciertos   elementos \n"
     ]
    }
   ],
   "source": [
    "solo_letras=re.sub(\"[^a-zA-Z]\", # El patrón a buscar: todo lo que no sean letras.\n",
    "                      \" \",     # El patrón con el que reemplazar: espacio blanco.\n",
    "                      ejemplo1.get_text() )\n",
    "print(solo_letras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(solo_letras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado devuelto es una cadena de caracteres en la que todos aquellos que no son letras han sido reemplazados por un espacio en blanco. Habrá que partir esa cadena para obtener palabras individuales. Esto se hace con el método split(). Además, hay mayúsculas que hay que transformar en minúsculas con el método lower(). El resultado devuelto ya es una lista de palabras individuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['esto', 'es', 'una', 'prueba', 'para', 'reemplazar', 'ciertos', 'elementos']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "tokens1=solo_letras.lower().split()\n",
    "print(tokens1)\n",
    "print(type(tokens1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora toca eliminar las *stop words*. El resultado sigue siendo una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prueba', 'reemplazar', 'ciertos', 'elementos']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "palabras = [palabra for palabra in tokens1 if not palabra in spanish_stopwords]\n",
    "print(palabras)\n",
    "print(type(palabras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez comprobados los pasos de *tokenización* los agrupo todos en la función mi_tokenizer de forma que esté todo ordenado y sea más sencillo de usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mi_tokenizer( texto ):\n",
    "    # Función para convertir texto en bruto en una cadena de palabras significativas.\n",
    "    # La entrada es una sola cadena (cada uno de los comentarios de los clientes).\n",
    "    # La salida es una sola cadena con las palabras de la crítica.\n",
    "    \n",
    "    # 1. Se limpia el texto de código HTML si lo hubiera.\n",
    "    texto_limpio = BeautifulSoup(texto).get_text() \n",
    "    \n",
    "    # 2. Se eliminan todos aquellos caracteres que no sean letras (incluye tildes).        \n",
    "    solo_letras = re.sub(\"[^a-zA-ZñÑáéíóúüÁÉÍÓÚÜ]\", \" \", texto_limpio) \n",
    "\n",
    "    # 3. Se convierte en minúsculas y se divide en palabras individuales.\n",
    "    solo_palabras = solo_letras.lower().split()                             \n",
    "    \n",
    "    # 4. Convierto la lista de stop words en un set porque en Python es mucho más\n",
    "    #   rápido buscar en un set que en una lista y se va a usar miles de veces.\n",
    "    stops = set(stopwords.words(\"spanish\"))                  \n",
    " \n",
    "    # 5. Se eliminan las stop words.\n",
    "    palabras_significativas=[palabra for palabra in solo_palabras if not palabra in stops]   \n",
    "\n",
    "    # 6. Se juntan de nuevo en una cadena las palabras separadas por espacios.\n",
    "    \n",
    "    return( \" \".join( palabras_significativas ))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hago un par de pruebas de tokenizar un solo elemento de los comentarios y luego dos para comprobar que se devuelve una lista de cadenas, una para cada comentario.  \n",
    "Veo que las palabras devueltas son exactamente las mismas 17 que en la solución 1. Para el segundo comentario devuelve 9 palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chicas perfecto esfera grande correa adapta muñecas finas pelín gordo gusto carga movimiento dura después días llevarlo\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casy\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file C:\\Users\\Casy\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "limpio=mi_tokenizer(comentarios[0])\n",
    "print(limpio)\n",
    "print(type(limpio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chicas perfecto esfera grande correa adapta muñecas finas pelín gordo gusto carga movimiento dura después días llevarlo', 'floja cuerda anclaje mala calidad metal dobla fácilmente recomiendo']\n",
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casy\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file C:\\Users\\Casy\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "limpio1=[]\n",
    "\n",
    "for i in range(2):\n",
    "    limpio1.append(mi_tokenizer(comentarios[i]))\n",
    "\n",
    "print(limpio1)\n",
    "print(type(limpio1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciona correctamente. Ya puedo generar los subconjuntos de entrenamiento (75%) y test (25%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526834\n",
      "175612\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "train=comentarios[:526834]\n",
    "test=comentarios[526834:]\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "print(type(train))\n",
    "print(type(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casy\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file C:\\Users\\Casy\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comentario 2000 de 526834\n",
      " procesado.\n",
      "Comentario 4000 de 526834\n",
      " procesado.\n",
      "Comentario 6000 de 526834\n",
      " procesado.\n",
      "Comentario 8000 de 526834\n",
      " procesado.\n",
      "Comentario 10000 de 526834\n",
      " procesado.\n",
      "Comentario 12000 de 526834\n",
      " procesado.\n",
      "Comentario 14000 de 526834\n",
      " procesado.\n",
      "Comentario 16000 de 526834\n",
      " procesado.\n",
      "Comentario 18000 de 526834\n",
      " procesado.\n",
      "Comentario 20000 de 526834\n",
      " procesado.\n",
      "Comentario 22000 de 526834\n",
      " procesado.\n",
      "Comentario 24000 de 526834\n",
      " procesado.\n",
      "Comentario 26000 de 526834\n",
      " procesado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casy\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.......... ............. ............. ......... ....... ...... ......... ............. ........ ..... ........ ...... ...... ...... .......... ........... .......... .......... ....... .....'\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comentario 28000 de 526834\n",
      " procesado.\n",
      "Comentario 30000 de 526834\n",
      " procesado.\n",
      "Comentario 32000 de 526834\n",
      " procesado.\n",
      "Comentario 34000 de 526834\n",
      " procesado.\n",
      "Comentario 36000 de 526834\n",
      " procesado.\n",
      "Comentario 38000 de 526834\n",
      " procesado.\n",
      "Comentario 40000 de 526834\n",
      " procesado.\n",
      "Comentario 42000 de 526834\n",
      " procesado.\n",
      "Comentario 44000 de 526834\n",
      " procesado.\n",
      "Comentario 46000 de 526834\n",
      " procesado.\n",
      "Comentario 48000 de 526834\n",
      " procesado.\n",
      "Comentario 50000 de 526834\n",
      " procesado.\n",
      "Comentario 52000 de 526834\n",
      " procesado.\n",
      "Comentario 54000 de 526834\n",
      " procesado.\n",
      "Comentario 56000 de 526834\n",
      " procesado.\n",
      "Comentario 58000 de 526834\n",
      " procesado.\n",
      "Comentario 60000 de 526834\n",
      " procesado.\n",
      "Comentario 62000 de 526834\n",
      " procesado.\n",
      "Comentario 64000 de 526834\n",
      " procesado.\n",
      "Comentario 66000 de 526834\n",
      " procesado.\n",
      "Comentario 68000 de 526834\n",
      " procesado.\n",
      "Comentario 70000 de 526834\n",
      " procesado.\n",
      "Comentario 72000 de 526834\n",
      " procesado.\n",
      "Comentario 74000 de 526834\n",
      " procesado.\n",
      "Comentario 76000 de 526834\n",
      " procesado.\n",
      "Comentario 78000 de 526834\n",
      " procesado.\n",
      "Comentario 80000 de 526834\n",
      " procesado.\n",
      "Comentario 82000 de 526834\n",
      " procesado.\n",
      "Comentario 84000 de 526834\n",
      " procesado.\n",
      "Comentario 86000 de 526834\n",
      " procesado.\n",
      "Comentario 88000 de 526834\n",
      " procesado.\n",
      "Comentario 90000 de 526834\n",
      " procesado.\n",
      "Comentario 92000 de 526834\n",
      " procesado.\n",
      "Comentario 94000 de 526834\n",
      " procesado.\n",
      "Comentario 96000 de 526834\n",
      " procesado.\n",
      "Comentario 98000 de 526834\n",
      " procesado.\n",
      "Comentario 100000 de 526834\n",
      " procesado.\n",
      "Comentario 102000 de 526834\n",
      " procesado.\n",
      "Comentario 104000 de 526834\n",
      " procesado.\n",
      "Comentario 106000 de 526834\n",
      " procesado.\n",
      "Comentario 108000 de 526834\n",
      " procesado.\n",
      "Comentario 110000 de 526834\n",
      " procesado.\n",
      "Comentario 112000 de 526834\n",
      " procesado.\n",
      "Comentario 114000 de 526834\n",
      " procesado.\n",
      "Comentario 116000 de 526834\n",
      " procesado.\n",
      "Comentario 118000 de 526834\n",
      " procesado.\n",
      "Comentario 120000 de 526834\n",
      " procesado.\n",
      "Comentario 122000 de 526834\n",
      " procesado.\n",
      "Comentario 124000 de 526834\n",
      " procesado.\n",
      "Comentario 126000 de 526834\n",
      " procesado.\n",
      "Comentario 128000 de 526834\n",
      " procesado.\n",
      "Comentario 130000 de 526834\n",
      " procesado.\n",
      "Comentario 132000 de 526834\n",
      " procesado.\n",
      "Comentario 134000 de 526834\n",
      " procesado.\n",
      "Comentario 136000 de 526834\n",
      " procesado.\n",
      "Comentario 138000 de 526834\n",
      " procesado.\n",
      "Comentario 140000 de 526834\n",
      " procesado.\n",
      "Comentario 142000 de 526834\n",
      " procesado.\n",
      "Comentario 144000 de 526834\n",
      " procesado.\n",
      "Comentario 146000 de 526834\n",
      " procesado.\n",
      "Comentario 148000 de 526834\n",
      " procesado.\n",
      "Comentario 150000 de 526834\n",
      " procesado.\n",
      "Comentario 152000 de 526834\n",
      " procesado.\n",
      "Comentario 154000 de 526834\n",
      " procesado.\n",
      "Comentario 156000 de 526834\n",
      " procesado.\n",
      "Comentario 158000 de 526834\n",
      " procesado.\n",
      "Comentario 160000 de 526834\n",
      " procesado.\n",
      "Comentario 162000 de 526834\n",
      " procesado.\n",
      "Comentario 164000 de 526834\n",
      " procesado.\n",
      "Comentario 166000 de 526834\n",
      " procesado.\n",
      "Comentario 168000 de 526834\n",
      " procesado.\n",
      "Comentario 170000 de 526834\n",
      " procesado.\n",
      "Comentario 172000 de 526834\n",
      " procesado.\n",
      "Comentario 174000 de 526834\n",
      " procesado.\n",
      "Comentario 176000 de 526834\n",
      " procesado.\n",
      "Comentario 178000 de 526834\n",
      " procesado.\n",
      "Comentario 180000 de 526834\n",
      " procesado.\n",
      "Comentario 182000 de 526834\n",
      " procesado.\n",
      "Comentario 184000 de 526834\n",
      " procesado.\n",
      "Comentario 186000 de 526834\n",
      " procesado.\n",
      "Comentario 188000 de 526834\n",
      " procesado.\n",
      "Comentario 190000 de 526834\n",
      " procesado.\n",
      "Comentario 192000 de 526834\n",
      " procesado.\n",
      "Comentario 194000 de 526834\n",
      " procesado.\n",
      "Comentario 196000 de 526834\n",
      " procesado.\n",
      "Comentario 198000 de 526834\n",
      " procesado.\n",
      "Comentario 200000 de 526834\n",
      " procesado.\n",
      "Comentario 202000 de 526834\n",
      " procesado.\n",
      "Comentario 204000 de 526834\n",
      " procesado.\n",
      "Comentario 206000 de 526834\n",
      " procesado.\n",
      "Comentario 208000 de 526834\n",
      " procesado.\n",
      "Comentario 210000 de 526834\n",
      " procesado.\n",
      "Comentario 212000 de 526834\n",
      " procesado.\n",
      "Comentario 214000 de 526834\n",
      " procesado.\n",
      "Comentario 216000 de 526834\n",
      " procesado.\n",
      "Comentario 218000 de 526834\n",
      " procesado.\n",
      "Comentario 220000 de 526834\n",
      " procesado.\n",
      "Comentario 222000 de 526834\n",
      " procesado.\n",
      "Comentario 224000 de 526834\n",
      " procesado.\n",
      "Comentario 226000 de 526834\n",
      " procesado.\n",
      "Comentario 228000 de 526834\n",
      " procesado.\n",
      "Comentario 230000 de 526834\n",
      " procesado.\n",
      "Comentario 232000 de 526834\n",
      " procesado.\n",
      "Comentario 234000 de 526834\n",
      " procesado.\n",
      "Comentario 236000 de 526834\n",
      " procesado.\n",
      "Comentario 238000 de 526834\n",
      " procesado.\n",
      "Comentario 240000 de 526834\n",
      " procesado.\n",
      "Comentario 242000 de 526834\n",
      " procesado.\n",
      "Comentario 244000 de 526834\n",
      " procesado.\n",
      "Comentario 246000 de 526834\n",
      " procesado.\n",
      "Comentario 248000 de 526834\n",
      " procesado.\n",
      "Comentario 250000 de 526834\n",
      " procesado.\n",
      "Comentario 252000 de 526834\n",
      " procesado.\n",
      "Comentario 254000 de 526834\n",
      " procesado.\n",
      "Comentario 256000 de 526834\n",
      " procesado.\n",
      "Comentario 258000 de 526834\n",
      " procesado.\n",
      "Comentario 260000 de 526834\n",
      " procesado.\n",
      "Comentario 262000 de 526834\n",
      " procesado.\n",
      "Comentario 264000 de 526834\n",
      " procesado.\n",
      "Comentario 266000 de 526834\n",
      " procesado.\n",
      "Comentario 268000 de 526834\n",
      " procesado.\n",
      "Comentario 270000 de 526834\n",
      " procesado.\n",
      "Comentario 272000 de 526834\n",
      " procesado.\n",
      "Comentario 274000 de 526834\n",
      " procesado.\n",
      "Comentario 276000 de 526834\n",
      " procesado.\n",
      "Comentario 278000 de 526834\n",
      " procesado.\n",
      "Comentario 280000 de 526834\n",
      " procesado.\n",
      "Comentario 282000 de 526834\n",
      " procesado.\n",
      "Comentario 284000 de 526834\n",
      " procesado.\n",
      "Comentario 286000 de 526834\n",
      " procesado.\n",
      "Comentario 288000 de 526834\n",
      " procesado.\n",
      "Comentario 290000 de 526834\n",
      " procesado.\n",
      "Comentario 292000 de 526834\n",
      " procesado.\n",
      "Comentario 294000 de 526834\n",
      " procesado.\n",
      "Comentario 296000 de 526834\n",
      " procesado.\n",
      "Comentario 298000 de 526834\n",
      " procesado.\n",
      "Comentario 300000 de 526834\n",
      " procesado.\n",
      "Comentario 302000 de 526834\n",
      " procesado.\n",
      "Comentario 304000 de 526834\n",
      " procesado.\n",
      "Comentario 306000 de 526834\n",
      " procesado.\n",
      "Comentario 308000 de 526834\n",
      " procesado.\n",
      "Comentario 310000 de 526834\n",
      " procesado.\n",
      "Comentario 312000 de 526834\n",
      " procesado.\n",
      "Comentario 314000 de 526834\n",
      " procesado.\n",
      "Comentario 316000 de 526834\n",
      " procesado.\n",
      "Comentario 318000 de 526834\n",
      " procesado.\n",
      "Comentario 320000 de 526834\n",
      " procesado.\n",
      "Comentario 322000 de 526834\n",
      " procesado.\n",
      "Comentario 324000 de 526834\n",
      " procesado.\n",
      "Comentario 326000 de 526834\n",
      " procesado.\n",
      "Comentario 328000 de 526834\n",
      " procesado.\n",
      "Comentario 330000 de 526834\n",
      " procesado.\n",
      "Comentario 332000 de 526834\n",
      " procesado.\n",
      "Comentario 334000 de 526834\n",
      " procesado.\n",
      "Comentario 336000 de 526834\n",
      " procesado.\n",
      "Comentario 338000 de 526834\n",
      " procesado.\n",
      "Comentario 340000 de 526834\n",
      " procesado.\n",
      "Comentario 342000 de 526834\n",
      " procesado.\n",
      "Comentario 344000 de 526834\n",
      " procesado.\n",
      "Comentario 346000 de 526834\n",
      " procesado.\n",
      "Comentario 348000 de 526834\n",
      " procesado.\n",
      "Comentario 350000 de 526834\n",
      " procesado.\n",
      "Comentario 352000 de 526834\n",
      " procesado.\n",
      "Comentario 354000 de 526834\n",
      " procesado.\n",
      "Comentario 356000 de 526834\n",
      " procesado.\n",
      "Comentario 358000 de 526834\n",
      " procesado.\n",
      "Comentario 360000 de 526834\n",
      " procesado.\n",
      "Comentario 362000 de 526834\n",
      " procesado.\n",
      "Comentario 364000 de 526834\n",
      " procesado.\n",
      "Comentario 366000 de 526834\n",
      " procesado.\n",
      "Comentario 368000 de 526834\n",
      " procesado.\n",
      "Comentario 370000 de 526834\n",
      " procesado.\n",
      "Comentario 372000 de 526834\n",
      " procesado.\n",
      "Comentario 374000 de 526834\n",
      " procesado.\n",
      "Comentario 376000 de 526834\n",
      " procesado.\n",
      "Comentario 378000 de 526834\n",
      " procesado.\n",
      "Comentario 380000 de 526834\n",
      " procesado.\n",
      "Comentario 382000 de 526834\n",
      " procesado.\n",
      "Comentario 384000 de 526834\n",
      " procesado.\n",
      "Comentario 386000 de 526834\n",
      " procesado.\n",
      "Comentario 388000 de 526834\n",
      " procesado.\n",
      "Comentario 390000 de 526834\n",
      " procesado.\n",
      "Comentario 392000 de 526834\n",
      " procesado.\n",
      "Comentario 394000 de 526834\n",
      " procesado.\n",
      "Comentario 396000 de 526834\n",
      " procesado.\n",
      "Comentario 398000 de 526834\n",
      " procesado.\n",
      "Comentario 400000 de 526834\n",
      " procesado.\n",
      "Comentario 402000 de 526834\n",
      " procesado.\n",
      "Comentario 404000 de 526834\n",
      " procesado.\n",
      "Comentario 406000 de 526834\n",
      " procesado.\n",
      "Comentario 408000 de 526834\n",
      " procesado.\n",
      "Comentario 410000 de 526834\n",
      " procesado.\n",
      "Comentario 412000 de 526834\n",
      " procesado.\n",
      "Comentario 414000 de 526834\n",
      " procesado.\n",
      "Comentario 416000 de 526834\n",
      " procesado.\n",
      "Comentario 418000 de 526834\n",
      " procesado.\n",
      "Comentario 420000 de 526834\n",
      " procesado.\n",
      "Comentario 422000 de 526834\n",
      " procesado.\n",
      "Comentario 424000 de 526834\n",
      " procesado.\n",
      "Comentario 426000 de 526834\n",
      " procesado.\n",
      "Comentario 428000 de 526834\n",
      " procesado.\n",
      "Comentario 430000 de 526834\n",
      " procesado.\n",
      "Comentario 432000 de 526834\n",
      " procesado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casy\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'..... ... .. . .... . ....... ....... ... ..... ......... ............ ..... . ..... .... . ..... ... .... ... . ...... .'\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comentario 434000 de 526834\n",
      " procesado.\n",
      "Comentario 436000 de 526834\n",
      " procesado.\n",
      "Comentario 438000 de 526834\n",
      " procesado.\n",
      "Comentario 440000 de 526834\n",
      " procesado.\n",
      "Comentario 442000 de 526834\n",
      " procesado.\n",
      "Comentario 444000 de 526834\n",
      " procesado.\n",
      "Comentario 446000 de 526834\n",
      " procesado.\n",
      "Comentario 448000 de 526834\n",
      " procesado.\n",
      "Comentario 450000 de 526834\n",
      " procesado.\n",
      "Comentario 452000 de 526834\n",
      " procesado.\n",
      "Comentario 454000 de 526834\n",
      " procesado.\n",
      "Comentario 456000 de 526834\n",
      " procesado.\n",
      "Comentario 458000 de 526834\n",
      " procesado.\n",
      "Comentario 460000 de 526834\n",
      " procesado.\n",
      "Comentario 462000 de 526834\n",
      " procesado.\n",
      "Comentario 464000 de 526834\n",
      " procesado.\n",
      "Comentario 466000 de 526834\n",
      " procesado.\n",
      "Comentario 468000 de 526834\n",
      " procesado.\n",
      "Comentario 470000 de 526834\n",
      " procesado.\n",
      "Comentario 472000 de 526834\n",
      " procesado.\n",
      "Comentario 474000 de 526834\n",
      " procesado.\n",
      "Comentario 476000 de 526834\n",
      " procesado.\n",
      "Comentario 478000 de 526834\n",
      " procesado.\n",
      "Comentario 480000 de 526834\n",
      " procesado.\n",
      "Comentario 482000 de 526834\n",
      " procesado.\n",
      "Comentario 484000 de 526834\n",
      " procesado.\n",
      "Comentario 486000 de 526834\n",
      " procesado.\n",
      "Comentario 488000 de 526834\n",
      " procesado.\n",
      "Comentario 490000 de 526834\n",
      " procesado.\n",
      "Comentario 492000 de 526834\n",
      " procesado.\n",
      "Comentario 494000 de 526834\n",
      " procesado.\n",
      "Comentario 496000 de 526834\n",
      " procesado.\n",
      "Comentario 498000 de 526834\n",
      " procesado.\n",
      "Comentario 500000 de 526834\n",
      " procesado.\n",
      "Comentario 502000 de 526834\n",
      " procesado.\n",
      "Comentario 504000 de 526834\n",
      " procesado.\n",
      "Comentario 506000 de 526834\n",
      " procesado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casy\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'............. .................... ................ .............. .............. ........... . .... ..... .... .... ... ... ... ... ... ... ... ... ..'\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comentario 508000 de 526834\n",
      " procesado.\n",
      "Comentario 510000 de 526834\n",
      " procesado.\n",
      "Comentario 512000 de 526834\n",
      " procesado.\n",
      "Comentario 514000 de 526834\n",
      " procesado.\n",
      "Comentario 516000 de 526834\n",
      " procesado.\n",
      "Comentario 518000 de 526834\n",
      " procesado.\n",
      "Comentario 520000 de 526834\n",
      " procesado.\n",
      "Comentario 522000 de 526834\n",
      " procesado.\n",
      "Comentario 524000 de 526834\n",
      " procesado.\n",
      "Comentario 526000 de 526834\n",
      " procesado.\n",
      "['chicas perfecto esfera grande correa adapta muñecas finas pelín gordo gusto carga movimiento dura después días llevarlo', 'floja cuerda anclaje mala calidad metal dobla fácilmente recomiendo']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "limpio_train=[]\n",
    "\n",
    "for i in range(len(train)):\n",
    "    if( (i+1)%2000 == 0 ):\n",
    "        print (\"Comentario %d de %d\\n procesado.\" % ( i+1, len(train) ))\n",
    "    limpio_train.append(mi_tokenizer(train[i]))\n",
    "\n",
    "print(limpio_train[:2])\n",
    "print(type(limpio_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este paso le llevó al PC unas 12 horas de cómputo.  \n",
    "A continuación genero una instancia de la clase CountVectorizer sin apenas pasarle atributos puesto que el proceso de *tokenize* ya lo he hecho de manera personalizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer = \"word\",  \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None)\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hago una prueba aplicando el método fit_transform() a la lista de prueba de dos elementos con sendas cadenas que contienen las palabras de los dos primeros comentarios.  \n",
    "Este método transforma las cadenas de palabras en una matriz dispersa (*sparse matrix*) con 26 elementos, correspondientes a 26 palabras. Esto es correcto puesto que, como se acaba de ver unas celdas más arriba, el primer comentario produce 17 palabras y el segundo 9. Cada fila de la matriz corresponde a un comentario (documento de texto) y cada columna a una palabra distinta. En cada celda de la matriz se coloca la cantidad de veces que una determinada palabra aparece en un determinado comentario.  \n",
    "Una matriz dispersa es una matriz grande en la que la mayoría de sus términos son nulos. Aquí aparecen las matrices dispersas porque la mayoría de las pocas palabras de un determinado comentario no aparecen en los demás. Por tanto, en las celdas correspondientes habrá ceros. Como son muchísimos comentarios, habrá muchísimos ceros. Esta información ocuparía mucha memoria. Por tanto, lo que se hace es almacenar solo los términos no nulos de la matriz en un formato compacto, CSR (Compressed Sparse Row format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x26 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 26 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_prueba = vectorizer2.fit_transform(limpio1)\n",
    "bag_prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez comprobado que funciona, aplico el método fit_transform() a la lista con todos los comentarios del conjunto de entrenamiento. Este método sirve para dos cosas: para ajustar el modelo y para generar la matriz dispersa del *bag of words*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<526834x224646 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11316265 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words = vectorizer2.fit_transform(limpio_train)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz dispersa consta de 526834 filas, correspondientes a los 526834 comentarios del conjunto de entrenamiento, y 224646 columnas, correspondientes a las 224646 palabras significativas del corpus de comentarios, es decir, el *bag of words* está formado por 224646 palabras.  \n",
    "Puedo mirar el vocabulario del *bag of words* del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "vocabulario = vectorizer2.get_feature_names()\n",
    "print(type(vocabulario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['impulsivos',\n",
       " 'impulso',\n",
       " 'impulsor',\n",
       " 'impulsora',\n",
       " 'impulsos',\n",
       " 'impulsándola',\n",
       " 'impulsé',\n",
       " 'impulsó',\n",
       " 'impune',\n",
       " 'impunemente',\n",
       " 'impunes',\n",
       " 'impunidad',\n",
       " 'impuntuales',\n",
       " 'impuntualidad',\n",
       " 'impura',\n",
       " 'impureza',\n",
       " 'impurezas',\n",
       " 'impuridades',\n",
       " 'impuro',\n",
       " 'impuros']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulario[110030:110050]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve que hay palabras muy parecidas con el mismo lexema. Podría ser útil llevar a cabo un proceso de stemming para considerar todas las pertenecientes a la misma familia como una sola.  \n",
    "Paso ahora a crear un modelo Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genero una instancia de Random Forests con 100 árboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bosque = RandomForestClassifier(n_estimators = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora entreno el modelo con las palabras del *bag of words* como *features* y los valores del sentimiento (pos o neg) como *target*. Este proceso duró unas 9 horas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bosque_entrenado = bosque.fit( bag_of_words, punt[:526834] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=30, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bosque_entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, queda aplicar el modelo entrenado al conjunto de *test*. Antes hay que transformar este conjunto de la misma forma que se hizo con el de entrenamiento. El proceso requirió unas 4 horas (claro, un tercio del tiempo para el de entrenamiento). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casy\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file C:\\Users\\Casy\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comentario 2000 de 175612 procesado.\n",
      "\n",
      "Comentario 4000 de 175612 procesado.\n",
      "\n",
      "Comentario 6000 de 175612 procesado.\n",
      "\n",
      "Comentario 8000 de 175612 procesado.\n",
      "\n",
      "Comentario 10000 de 175612 procesado.\n",
      "\n",
      "Comentario 12000 de 175612 procesado.\n",
      "\n",
      "Comentario 14000 de 175612 procesado.\n",
      "\n",
      "Comentario 16000 de 175612 procesado.\n",
      "\n",
      "Comentario 18000 de 175612 procesado.\n",
      "\n",
      "Comentario 20000 de 175612 procesado.\n",
      "\n",
      "Comentario 22000 de 175612 procesado.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casy\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'........... .............. .............. ............. ............. ............... ............. .......... ........ . . ............ . ............. . . ...... ........ ...... ........'\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comentario 24000 de 175612 procesado.\n",
      "\n",
      "Comentario 26000 de 175612 procesado.\n",
      "\n",
      "Comentario 28000 de 175612 procesado.\n",
      "\n",
      "Comentario 30000 de 175612 procesado.\n",
      "\n",
      "Comentario 32000 de 175612 procesado.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casy\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comentario 34000 de 175612 procesado.\n",
      "\n",
      "Comentario 36000 de 175612 procesado.\n",
      "\n",
      "Comentario 38000 de 175612 procesado.\n",
      "\n",
      "Comentario 40000 de 175612 procesado.\n",
      "\n",
      "Comentario 42000 de 175612 procesado.\n",
      "\n",
      "Comentario 44000 de 175612 procesado.\n",
      "\n",
      "Comentario 46000 de 175612 procesado.\n",
      "\n",
      "Comentario 48000 de 175612 procesado.\n",
      "\n",
      "Comentario 50000 de 175612 procesado.\n",
      "\n",
      "Comentario 52000 de 175612 procesado.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casy\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'....... ........ ...... .. .. . ......... ....... ....... ...... .. ... ...... ..... ........ ...... ...... .... ........ .'\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comentario 54000 de 175612 procesado.\n",
      "\n",
      "Comentario 56000 de 175612 procesado.\n",
      "\n",
      "Comentario 58000 de 175612 procesado.\n",
      "\n",
      "Comentario 60000 de 175612 procesado.\n",
      "\n",
      "Comentario 62000 de 175612 procesado.\n",
      "\n",
      "Comentario 64000 de 175612 procesado.\n",
      "\n",
      "Comentario 66000 de 175612 procesado.\n",
      "\n",
      "Comentario 68000 de 175612 procesado.\n",
      "\n",
      "Comentario 70000 de 175612 procesado.\n",
      "\n",
      "Comentario 72000 de 175612 procesado.\n",
      "\n",
      "Comentario 74000 de 175612 procesado.\n",
      "\n",
      "Comentario 76000 de 175612 procesado.\n",
      "\n",
      "Comentario 78000 de 175612 procesado.\n",
      "\n",
      "Comentario 80000 de 175612 procesado.\n",
      "\n",
      "Comentario 82000 de 175612 procesado.\n",
      "\n",
      "Comentario 84000 de 175612 procesado.\n",
      "\n",
      "Comentario 86000 de 175612 procesado.\n",
      "\n",
      "Comentario 88000 de 175612 procesado.\n",
      "\n",
      "Comentario 90000 de 175612 procesado.\n",
      "\n",
      "Comentario 92000 de 175612 procesado.\n",
      "\n",
      "Comentario 94000 de 175612 procesado.\n",
      "\n",
      "Comentario 96000 de 175612 procesado.\n",
      "\n",
      "Comentario 98000 de 175612 procesado.\n",
      "\n",
      "Comentario 100000 de 175612 procesado.\n",
      "\n",
      "Comentario 102000 de 175612 procesado.\n",
      "\n",
      "Comentario 104000 de 175612 procesado.\n",
      "\n",
      "Comentario 106000 de 175612 procesado.\n",
      "\n",
      "Comentario 108000 de 175612 procesado.\n",
      "\n",
      "Comentario 110000 de 175612 procesado.\n",
      "\n",
      "Comentario 112000 de 175612 procesado.\n",
      "\n",
      "Comentario 114000 de 175612 procesado.\n",
      "\n",
      "Comentario 116000 de 175612 procesado.\n",
      "\n",
      "Comentario 118000 de 175612 procesado.\n",
      "\n",
      "Comentario 120000 de 175612 procesado.\n",
      "\n",
      "Comentario 122000 de 175612 procesado.\n",
      "\n",
      "Comentario 124000 de 175612 procesado.\n",
      "\n",
      "Comentario 126000 de 175612 procesado.\n",
      "\n",
      "Comentario 128000 de 175612 procesado.\n",
      "\n",
      "Comentario 130000 de 175612 procesado.\n",
      "\n",
      "Comentario 132000 de 175612 procesado.\n",
      "\n",
      "Comentario 134000 de 175612 procesado.\n",
      "\n",
      "Comentario 136000 de 175612 procesado.\n",
      "\n",
      "Comentario 138000 de 175612 procesado.\n",
      "\n",
      "Comentario 140000 de 175612 procesado.\n",
      "\n",
      "Comentario 142000 de 175612 procesado.\n",
      "\n",
      "Comentario 144000 de 175612 procesado.\n",
      "\n",
      "Comentario 146000 de 175612 procesado.\n",
      "\n",
      "Comentario 148000 de 175612 procesado.\n",
      "\n",
      "Comentario 150000 de 175612 procesado.\n",
      "\n",
      "Comentario 152000 de 175612 procesado.\n",
      "\n",
      "Comentario 154000 de 175612 procesado.\n",
      "\n",
      "Comentario 156000 de 175612 procesado.\n",
      "\n",
      "Comentario 158000 de 175612 procesado.\n",
      "\n",
      "Comentario 160000 de 175612 procesado.\n",
      "\n",
      "Comentario 162000 de 175612 procesado.\n",
      "\n",
      "Comentario 164000 de 175612 procesado.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casy\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.......... ............ ............ ............... .............. ............... ........... ............ ............ ...... ........... ..  . .. ....  ..... .... .... .... ...  .....'\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comentario 166000 de 175612 procesado.\n",
      "\n",
      "Comentario 168000 de 175612 procesado.\n",
      "\n",
      "Comentario 170000 de 175612 procesado.\n",
      "\n",
      "Comentario 172000 de 175612 procesado.\n",
      "\n",
      "Comentario 174000 de 175612 procesado.\n",
      "\n",
      "['aunque costo esperaba mejor instalación software manejo sencillo pesar venir inglés calidad imagen sacar fotos grabar vídeos escasa', 'pueden ver películas si conecto disco duro tv visto comentarios necesita ser multimedia así alguien probado']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "limpio_test=[]\n",
    "\n",
    "for i in range(len(test)):\n",
    "    if( (i+1)%2000 == 0 ):\n",
    "        print (\"Comentario %d de %d procesado.\\n\" % ( i+1, len(test) ))\n",
    "    limpio_test.append(mi_tokenizer(test[i]))\n",
    "\n",
    "print(limpio_test[:2])\n",
    "print(type(limpio_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del mismo modo, genero el *bag of words* del conjunto de test. Ahora, en cambio, no se le aplica el método fit_transform() sino transform() porque aquel era para ajustar el modelo con el conjunto de entrenamiento (y obtener la matriz dispersa correspondiente) y ahora solo se necesita obtener la representación de *bag of words* con la matriz dispersa del conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_of_words_test = vectorizer2.transform(limpio_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<175612x224646 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3743352 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "resultado=bosque_entrenado.predict(bag_of_words_test)\n",
    "print(type(resultado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neg', 'neg', 'pos', 'pos', 'neg', 'neg', 'neg', 'pos', 'neg',\n",
       "       'neg', 'pos', 'pos', 'neg', 'pos', 'pos'], \n",
       "      dtype='<U3')"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79147780333917961"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bosque_entrenado.score(bag_of_words_test,punt[526834:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede apreciarse, la precisión de este modelo con Random Forest es algo inferior al de la solución 1 con Naïve Bayes. Además, este modelo ha tardado unas 25 veces más en completar su ejecución. Nótese que la otra solución trabajaba con diccionarios, mientras que esta lo hacía con listas. Y es mucho más rápido buscar dentro de un set o un diccionario que en una lista.\n",
    "\n",
    "Podría conseguirse mejor precisión realizando un proceso de stemming previo para unificar todas las palabras con el mismo lexema. El uso de bigrams también podría incrementar la tasa de aciertos. Pero quizá sea más útil en un idioma como el inglés, donde existen muchas palabras compuestas, que en uno como el español, en que no es tan habitual la construcción de palabras mediante composición."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
